{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1 은 Bag-of-words 모델을 사용하여 IMDB 리뷰의 sentiment 를 분석한다. Bag-of-words 는 문장에 들어있는 단어의 빈도 수를 근거로 분류를 하는 방법으로, 문법이나 반어적 표현을 해석하는 데에는 한계가 존재한다. (https://en.wikipedia.org/wiki/Bag-of-words_model) 이를 보완하기 위한 방법으로 n-gram (연속되는 n 개의 단어로 분석)이 있다. 이 노트북에서는 Bag-of-words 모델을 사용하여 감상 분류를 해본다.\n",
    "\n",
    "## 순서\n",
    "1) 데이터 전처리\n",
    "\n",
    "2) 전처리된 review 를 vectorize. 이때 bag-of-words 모델 사용\n",
    "\n",
    "3) Random Forest 모델로 학습 후 test set 에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  sentiment                                             review\n",
      "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
      "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
      "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
      "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
      "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ... \n",
      "\n",
      "\"With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally sta\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('labeledTrainData.tsv', header=0, sep='\\t', quoting=3)\n",
    "print(train.head(),'\\n')\n",
    "print(train['review'][0][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 데이터 전처리\n",
    "아래와 같은 전처리 과정을 거쳐서 의미있는 단어들의 구성으로 만든다.\n",
    "1. html 제거 (w/ BeautifulSoup)\n",
    "2. 특수문자 제거 (w/ re)\n",
    "3. 줄글을 단어 리스트로 변환\n",
    "4. 기능어 제거 (w/ nltk stopword)\n",
    "5. stemmer 로 어간 추출\n",
    "6. 리스트를 text 로 변환 후 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. html 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.The actual feature film bit when it finally starts is only on for 20 mi'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train['review'][0] 을 대상으로 전처리 함수를 만들고, 그 후 apply 로 일괄 적용\n",
    "# html 은 BeautifulSoup 으로 제거\n",
    "from bs4 import BeautifulSoup\n",
    "train_html_parser = BeautifulSoup(train['review'][0], 'html.parser')\n",
    "train_html_parser.get_text()[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 특수문자 제거 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' With all this stuff going down at the moment with MJ i ve started listening to his music  watching the odd documentary here and there  watched The Wiz and watched Moonwalker again  Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent  Moonwalker is part biography  part feature film which i remember going to see at the cinema when it was originally released  Some of it has subtle messages about MJ s feeling towards the press and also the obvious message of drugs are bad m kay Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring  Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him The actual feature film bit when it finally starts is only on for    mi'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 특수문자 제거는 정규식을 사용. 알파벳이 아닌 str 을 공백으로 대체\n",
    "import re\n",
    "train_letters = re.sub('[^a-zA-Z]', ' ', train_html_parser.get_text())\n",
    "#train_letters = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', ' ', train_html_parser.get_text()) #이렇게 할 경우 I've 에 사용되는 따옴표도 제거됨.\n",
    "#train_html_parser.get_text()[:1000]\n",
    "train_letters[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 소문자로 바꾼 후 리스트로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['with',\n",
       " 'all',\n",
       " 'this',\n",
       " 'stuff',\n",
       " 'going',\n",
       " 'down',\n",
       " 'at',\n",
       " 'the',\n",
       " 'moment',\n",
       " 'with',\n",
       " 'mj',\n",
       " 'i',\n",
       " 've',\n",
       " 'started',\n",
       " 'listening',\n",
       " 'to',\n",
       " 'his',\n",
       " 'music',\n",
       " 'watching',\n",
       " 'the',\n",
       " 'odd',\n",
       " 'documentary',\n",
       " 'here',\n",
       " 'and',\n",
       " 'there',\n",
       " 'watched',\n",
       " 'the',\n",
       " 'wiz',\n",
       " 'and',\n",
       " 'watched',\n",
       " 'moonwalker',\n",
       " 'again',\n",
       " 'maybe',\n",
       " 'i',\n",
       " 'just',\n",
       " 'want',\n",
       " 'to',\n",
       " 'get',\n",
       " 'a',\n",
       " 'certain',\n",
       " 'insight',\n",
       " 'into',\n",
       " 'this',\n",
       " 'guy',\n",
       " 'who',\n",
       " 'i',\n",
       " 'thought',\n",
       " 'was',\n",
       " 'really',\n",
       " 'cool',\n",
       " 'in',\n",
       " 'the',\n",
       " 'eighties',\n",
       " 'just',\n",
       " 'to',\n",
       " 'maybe',\n",
       " 'make',\n",
       " 'up',\n",
       " 'my',\n",
       " 'mind',\n",
       " 'whether',\n",
       " 'he',\n",
       " 'is',\n",
       " 'guilty',\n",
       " 'or',\n",
       " 'innocent',\n",
       " 'moonwalker',\n",
       " 'is',\n",
       " 'part',\n",
       " 'biography',\n",
       " 'part',\n",
       " 'feature',\n",
       " 'film',\n",
       " 'which',\n",
       " 'i',\n",
       " 'remember',\n",
       " 'going',\n",
       " 'to',\n",
       " 'see',\n",
       " 'at',\n",
       " 'the',\n",
       " 'cinema',\n",
       " 'when',\n",
       " 'it',\n",
       " 'was',\n",
       " 'originally',\n",
       " 'released',\n",
       " 'some',\n",
       " 'of',\n",
       " 'it',\n",
       " 'has',\n",
       " 'subtle',\n",
       " 'messages',\n",
       " 'about',\n",
       " 'mj',\n",
       " 's',\n",
       " 'feeling',\n",
       " 'towards',\n",
       " 'the',\n",
       " 'press',\n",
       " 'and',\n",
       " 'also',\n",
       " 'the',\n",
       " 'obvious',\n",
       " 'message',\n",
       " 'of',\n",
       " 'drugs',\n",
       " 'are',\n",
       " 'bad',\n",
       " 'm',\n",
       " 'kay',\n",
       " 'visually',\n",
       " 'impressive',\n",
       " 'but',\n",
       " 'of',\n",
       " 'course',\n",
       " 'this',\n",
       " 'is',\n",
       " 'all',\n",
       " 'about',\n",
       " 'michael',\n",
       " 'jackson',\n",
       " 'so',\n",
       " 'unless',\n",
       " 'you',\n",
       " 'remotely',\n",
       " 'like',\n",
       " 'mj',\n",
       " 'in',\n",
       " 'anyway',\n",
       " 'then',\n",
       " 'you',\n",
       " 'are',\n",
       " 'going',\n",
       " 'to',\n",
       " 'hate',\n",
       " 'this',\n",
       " 'and',\n",
       " 'find',\n",
       " 'it',\n",
       " 'boring',\n",
       " 'some',\n",
       " 'may',\n",
       " 'call',\n",
       " 'mj',\n",
       " 'an',\n",
       " 'egotist',\n",
       " 'for',\n",
       " 'consenting',\n",
       " 'to',\n",
       " 'the',\n",
       " 'making',\n",
       " 'of',\n",
       " 'this',\n",
       " 'movie',\n",
       " 'but',\n",
       " 'mj',\n",
       " 'and',\n",
       " 'most',\n",
       " 'of',\n",
       " 'his',\n",
       " 'fans',\n",
       " 'would',\n",
       " 'say',\n",
       " 'that',\n",
       " 'he',\n",
       " 'made',\n",
       " 'it',\n",
       " 'for',\n",
       " 'the',\n",
       " 'fans',\n",
       " 'which',\n",
       " 'if',\n",
       " 'true',\n",
       " 'is',\n",
       " 'really',\n",
       " 'nice',\n",
       " 'of',\n",
       " 'him',\n",
       " 'the',\n",
       " 'actual',\n",
       " 'feature',\n",
       " 'film',\n",
       " 'bit',\n",
       " 'when',\n",
       " 'it',\n",
       " 'finally',\n",
       " 'starts',\n",
       " 'is',\n",
       " 'only',\n",
       " 'on',\n",
       " 'for',\n",
       " 'minutes',\n",
       " 'or',\n",
       " 'so',\n",
       " 'excluding',\n",
       " 'the',\n",
       " 'smooth',\n",
       " 'criminal',\n",
       " 'sequence']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특수문자를 없앤 후 소문자로 변환 후, words list 를 만든다. \n",
    "train_words_list = train_letters.lower().split()\n",
    "train_words_list[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 기능어 제거 (불용어 제거)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stuff',\n",
       " 'going',\n",
       " 'moment',\n",
       " 'mj',\n",
       " 'started',\n",
       " 'listening',\n",
       " 'music',\n",
       " 'watching',\n",
       " 'odd',\n",
       " 'documentary',\n",
       " 'watched',\n",
       " 'wiz',\n",
       " 'watched',\n",
       " 'moonwalker',\n",
       " 'maybe',\n",
       " 'want',\n",
       " 'get',\n",
       " 'certain',\n",
       " 'insight',\n",
       " 'guy',\n",
       " 'thought',\n",
       " 'really',\n",
       " 'cool',\n",
       " 'eighties',\n",
       " 'maybe',\n",
       " 'make',\n",
       " 'mind',\n",
       " 'whether',\n",
       " 'guilty',\n",
       " 'innocent',\n",
       " 'moonwalker',\n",
       " 'part',\n",
       " 'biography',\n",
       " 'part',\n",
       " 'feature',\n",
       " 'film',\n",
       " 'remember',\n",
       " 'going',\n",
       " 'see',\n",
       " 'cinema',\n",
       " 'originally',\n",
       " 'released',\n",
       " 'subtle',\n",
       " 'messages',\n",
       " 'mj',\n",
       " 'feeling',\n",
       " 'towards',\n",
       " 'press',\n",
       " 'also',\n",
       " 'obvious',\n",
       " 'message',\n",
       " 'drugs',\n",
       " 'bad',\n",
       " 'kay',\n",
       " 'visually',\n",
       " 'impressive',\n",
       " 'course',\n",
       " 'michael',\n",
       " 'jackson',\n",
       " 'unless',\n",
       " 'remotely',\n",
       " 'like',\n",
       " 'mj',\n",
       " 'anyway',\n",
       " 'going',\n",
       " 'hate',\n",
       " 'find',\n",
       " 'boring',\n",
       " 'may',\n",
       " 'call',\n",
       " 'mj',\n",
       " 'egotist',\n",
       " 'consenting',\n",
       " 'making',\n",
       " 'movie',\n",
       " 'mj',\n",
       " 'fans',\n",
       " 'would',\n",
       " 'say',\n",
       " 'made',\n",
       " 'fans',\n",
       " 'true',\n",
       " 'really',\n",
       " 'nice',\n",
       " 'actual',\n",
       " 'feature',\n",
       " 'film',\n",
       " 'bit',\n",
       " 'finally',\n",
       " 'starts',\n",
       " 'minutes',\n",
       " 'excluding',\n",
       " 'smooth',\n",
       " 'criminal',\n",
       " 'sequence',\n",
       " 'joe',\n",
       " 'pesci',\n",
       " 'convincing',\n",
       " 'psychopathic',\n",
       " 'powerful',\n",
       " 'drug',\n",
       " 'lord',\n",
       " 'wants',\n",
       " 'mj',\n",
       " 'dead',\n",
       " 'bad',\n",
       " 'beyond',\n",
       " 'mj',\n",
       " 'overheard',\n",
       " 'plans',\n",
       " 'nah',\n",
       " 'joe',\n",
       " 'pesci',\n",
       " 'character',\n",
       " 'ranted',\n",
       " 'wanted',\n",
       " 'people',\n",
       " 'know',\n",
       " 'supplying',\n",
       " 'drugs',\n",
       " 'etc',\n",
       " 'dunno',\n",
       " 'maybe',\n",
       " 'hates',\n",
       " 'mj',\n",
       " 'music',\n",
       " 'lots',\n",
       " 'cool',\n",
       " 'things',\n",
       " 'like',\n",
       " 'mj',\n",
       " 'turning',\n",
       " 'car',\n",
       " 'robot',\n",
       " 'whole',\n",
       " 'speed',\n",
       " 'demon',\n",
       " 'sequence',\n",
       " 'also',\n",
       " 'director',\n",
       " 'must',\n",
       " 'patience',\n",
       " 'saint',\n",
       " 'came',\n",
       " 'filming',\n",
       " 'kiddy',\n",
       " 'bad',\n",
       " 'sequence',\n",
       " 'usually',\n",
       " 'directors',\n",
       " 'hate',\n",
       " 'working',\n",
       " 'one',\n",
       " 'kid',\n",
       " 'let',\n",
       " 'alone',\n",
       " 'whole',\n",
       " 'bunch',\n",
       " 'performing',\n",
       " 'complex',\n",
       " 'dance',\n",
       " 'scene',\n",
       " 'bottom',\n",
       " 'line',\n",
       " 'movie',\n",
       " 'people',\n",
       " 'like',\n",
       " 'mj',\n",
       " 'one',\n",
       " 'level',\n",
       " 'another',\n",
       " 'think',\n",
       " 'people',\n",
       " 'stay',\n",
       " 'away',\n",
       " 'try',\n",
       " 'give',\n",
       " 'wholesome',\n",
       " 'message',\n",
       " 'ironically',\n",
       " 'mj',\n",
       " 'bestest',\n",
       " 'buddy',\n",
       " 'movie',\n",
       " 'girl',\n",
       " 'michael',\n",
       " 'jackson',\n",
       " 'truly',\n",
       " 'one',\n",
       " 'talented',\n",
       " 'people',\n",
       " 'ever',\n",
       " 'grace',\n",
       " 'planet',\n",
       " 'guilty',\n",
       " 'well',\n",
       " 'attention',\n",
       " 'gave',\n",
       " 'subject',\n",
       " 'hmmm']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기능어를 제거하여 의미있는 단어들로만 구성한다. nltk stopwords 라이브러리 사용\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "train_meaningWords = [w for w in train_words_list if not w in stopwords]\n",
    "train_meaningWords[:200]\n",
    "# nltk 실행시 리소스 다운로드가 필요하다는 결과를 얻을 수 있음. 터미널에서 nltk.download('') 로 다운로드하면 해결됨\n",
    "# 결과로부터 all, this 와 같은 기능어가 제거된 것 확인 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 어간 추출  \n",
    "listening 과 litens, liten 은 같은 의미를 지녔기 때문에 어근을 추출하는 작업이 필요함. 이때 사용되는 것이 stemmer 인데, 여기서는 snowball stemmer 를 사용한다. http://www.nltk.org/howto/stem.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arabic danish dutch english finnish french german hungarian italian norwegian porter portuguese romanian russian spanish swedish\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "#SnowballStemmer 에서 제공하는 언어\n",
    "print(\" \".join(SnowballStemmer.languages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'watch'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "stemmer.stem('watching')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stuff',\n",
       " 'go',\n",
       " 'moment',\n",
       " 'mj',\n",
       " 'start',\n",
       " 'listen',\n",
       " 'music',\n",
       " 'watch',\n",
       " 'odd',\n",
       " 'documentari',\n",
       " 'watch',\n",
       " 'wiz',\n",
       " 'watch',\n",
       " 'moonwalk',\n",
       " 'mayb',\n",
       " 'want',\n",
       " 'get',\n",
       " 'certain',\n",
       " 'insight',\n",
       " 'guy']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_stem = [stemmer.stem(w) for w in train_meaningWords]\n",
    "word_stem[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리 함수 만들기\n",
    "review 글이 전처리된 words 로 구성된 text 를 반환하는 함수.\n",
    "새로웉 컬럼을 만들거나, text 를 출력하는 것은 결과를 처리하는 것에 따름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_words(sentence):\n",
    "    parsed_sentence = BeautifulSoup(sentence, 'html.parser').get_text()\n",
    "    letters_sentence = re.sub('[^a-zA-Z]', ' ', parsed_sentence)\n",
    "    words_lst = letters_sentence.lower().split()\n",
    "    \n",
    "    # stopwords 제거\n",
    "    from nltk.corpus import stopwords\n",
    "    stopwords = set(stopwords.words('english'))\n",
    "    meaning_words_lst = [w for w in words_lst if not w in stopwords]\n",
    "    \n",
    "    # 어근 추출\n",
    "    from nltk.stem.snowball import SnowballStemmer\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stem_words_lst = [stemmer.stem(w) for w in meaning_words_lst]\n",
    "    \n",
    "    return (' '.join(stem_words_lst))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time train['review_to_words']=train['review'].apply(review_to_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "      <th>review_to_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "      <td>\"with stuff go moment mj i'v start listen musi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "      <td>\"\\\"the classic war worlds\\\" timothi hine enter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "      <td>\"the film start manag (nichola bell) give welc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review  \\\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...   \n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...   \n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...   \n",
       "\n",
       "                                     review_to_words  \n",
       "0  \"with stuff go moment mj i'v start listen musi...  \n",
       "1  \"\\\"the classic war worlds\\\" timothi hine enter...  \n",
       "2  \"the film start manag (nichola bell) give welc...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 멀티프로세싱\n",
    "25000개의 데이터를 전처리할 때 더 표율적으로 하기 위하여 멀티프로세싱을 적용해볼 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 참고 : https://gist.github.com/yong27/7869662\n",
    "# http://www.racketracer.com/2016/07/06/pandas-in-parallel/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def _apply_df(args):\n",
    "    df, func, kwargs = args\n",
    "    return df.apply(func, **kwargs)\n",
    "\n",
    "def apply_by_multiprocessing(df, func, **kwargs):\n",
    "    workers = kwargs.pop('workers')\n",
    "    pool = multiprocessing.Pool(processes=workers)\n",
    "    result = pool.map(_apply_df, [(d, func, kwargs)\n",
    "            for d in np.array_split(df, workers)])\n",
    "    pool.close()\n",
    "    return pd.concat(list(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 152 ms, sys: 210 ms, total: 363 ms\n",
      "Wall time: 51.7 s\n"
     ]
    }
   ],
   "source": [
    "%time clean_train_reviews = apply_by_multiprocessing(train['review'], review_to_words, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(clean_train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 전처리된 review 를 vectorize\n",
    "Bag-of-words 모델: 각 review 에서 사용된 단어를 통틀어 하나의 dictionary 를 만들고, 각 review 에서 dictionary 의 단어의 사용 횟수에 대하여 vector 생성\n",
    "\n",
    "vector 로 변경할 때에는 sklearn 의 Countvector 를 사용 (https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=20000, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(lowercase = True, \n",
    "                             preprocessor = None,\n",
    "                             tokenizer = None, \n",
    "                             stop_words = None,\n",
    "                             analyzer = 'word',\n",
    "                             max_features=20000)\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.33 s, sys: 288 ms, total: 3.62 s\n",
      "Wall time: 3.67 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<25000x20000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2301515 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorizer 객체에 전처리된 review 를 바탕으로 dictionary 만든 후 벡터화 시키도록 한다. 이때 fit_transform 매서드 사용.\n",
    "# fit_transform 할 경우 vectorizer 도 학습이 되게 되고, 이를 바로 적용한 값을 출력한다.\n",
    "%time train_data_features = vectorizer.fit_transform(clean_train_reviews)\n",
    "train_data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 20000)\n"
     ]
    }
   ],
   "source": [
    "# vectorizer 를 실행한 결과, 각 row 별로 20,000 개의 단어 사용 횟수를 나타내는 vector 로 구성된 matrix 가 나온다. \n",
    "# 이를 array 형태로 바꾼다.\n",
    "train_data_features = train_data_features.toarray()\n",
    "print(train_data_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaa',\n",
       " 'aag',\n",
       " 'aam',\n",
       " 'aamir',\n",
       " 'aankhen',\n",
       " 'aapk',\n",
       " 'aardman',\n",
       " 'aaron',\n",
       " 'ab']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorizer 의 vocabulary dict 를 확인하는 작업\n",
    "vocab = vectorizer.get_feature_names()\n",
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "# 각 단어가 나온 횟수 세우기\n",
    "dist = np.sum(train_data_features, axis=0)\n",
    "print(len(vocab))\n",
    "print(len(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aa': 5,\n",
       " 'aaa': 9,\n",
       " 'aag': 26,\n",
       " 'aam': 15,\n",
       " 'aamir': 5,\n",
       " 'aankhen': 6,\n",
       " 'aapk': 6,\n",
       " 'aardman': 12,\n",
       " 'aaron': 48,\n",
       " 'ab': 22,\n",
       " 'aback': 9,\n",
       " 'abandon': 288,\n",
       " 'abba': 14,\n",
       " 'abbey': 24,\n",
       " 'abbi': 30,\n",
       " 'abbot': 29,\n",
       " 'abbott': 30,\n",
       " 'abbrevi': 6,\n",
       " 'abc': 125,\n",
       " 'abduct': 55,\n",
       " 'abductor': 5,\n",
       " 'abe': 24,\n",
       " 'abel': 9,\n",
       " 'aberr': 6,\n",
       " 'abet': 17,\n",
       " 'abhay': 28,\n",
       " 'abhishek': 9,\n",
       " 'abhorr': 20,\n",
       " 'abid': 28,\n",
       " 'abigail': 26,\n",
       " 'abil': 562,\n",
       " 'abject': 11,\n",
       " 'abl': 1259,\n",
       " 'abli': 27,\n",
       " 'abnorm': 16,\n",
       " 'abo': 14,\n",
       " 'aboard': 37,\n",
       " 'abod': 6,\n",
       " 'abolish': 6,\n",
       " 'abomin': 83,\n",
       " 'aborigin': 69,\n",
       " 'abort': 92,\n",
       " 'abound': 63,\n",
       " 'abraham': 93,\n",
       " 'abras': 14,\n",
       " 'abridg': 12,\n",
       " 'abroad': 38,\n",
       " 'abrupt': 136,\n",
       " 'abscond': 6,\n",
       " 'absenc': 118,\n",
       " 'absent': 83,\n",
       " 'absente': 5,\n",
       " 'absolut': 1850,\n",
       " 'absolutley': 5,\n",
       " 'absolv': 6,\n",
       " 'absorb': 154,\n",
       " 'absorpt': 6,\n",
       " 'abstract': 49,\n",
       " 'absurd': 427,\n",
       " 'absurdist': 18,\n",
       " 'abu': 40,\n",
       " 'abund': 73,\n",
       " 'abus': 398,\n",
       " 'abut': 5,\n",
       " 'abysm': 110,\n",
       " 'abyss': 19,\n",
       " 'ac': 10,\n",
       " 'academ': 41,\n",
       " 'academi': 298,\n",
       " 'acceler': 19,\n",
       " 'accent': 704,\n",
       " 'accentu': 30,\n",
       " 'accept': 781,\n",
       " 'access': 165,\n",
       " 'accessori': 8,\n",
       " 'accid': 344,\n",
       " 'accident': 246,\n",
       " 'acclaim': 118,\n",
       " 'accolad': 26,\n",
       " 'accommod': 24,\n",
       " 'accompani': 197,\n",
       " 'accomplic': 28,\n",
       " 'accomplish': 271,\n",
       " 'accord': 329,\n",
       " 'accost': 8,\n",
       " 'account': 297,\n",
       " 'accru': 5,\n",
       " 'accumul': 19,\n",
       " 'accur': 349,\n",
       " 'accuraci': 82,\n",
       " 'accus': 204,\n",
       " 'accustom': 24,\n",
       " 'ace': 75,\n",
       " 'acerb': 12,\n",
       " 'ach': 50,\n",
       " 'acharya': 10,\n",
       " 'achiev': 578,\n",
       " 'achill': 28,\n",
       " 'achillea': 5,\n",
       " 'acid': 102,\n",
       " 'ackland': 19,\n",
       " 'acknowledg': 109,\n",
       " 'ackroyd': 8,\n",
       " 'acm': 7,\n",
       " 'acolyt': 5,\n",
       " 'acorn': 6,\n",
       " 'acoust': 9,\n",
       " 'acquaint': 73,\n",
       " 'acquart': 5,\n",
       " 'acquir': 97,\n",
       " 'acquit': 28,\n",
       " 'acr': 23,\n",
       " 'acrobat': 29,\n",
       " 'across': 971,\n",
       " 'act': 8794,\n",
       " 'action': 3694,\n",
       " 'activ': 268,\n",
       " 'activist': 39,\n",
       " 'actor': 6876,\n",
       " 'actress': 1588,\n",
       " 'actual': 5065,\n",
       " 'acut': 18,\n",
       " 'ad': 793,\n",
       " 'ada': 29,\n",
       " 'adag': 6,\n",
       " 'adam': 414,\n",
       " 'adama': 14,\n",
       " 'adamson': 13,\n",
       " 'adapt': 835,\n",
       " 'add': 1147,\n",
       " 'addendum': 7,\n",
       " 'addi': 10,\n",
       " 'addict': 261,\n",
       " 'addison': 10,\n",
       " 'addit': 499,\n",
       " 'addl': 12,\n",
       " 'address': 183,\n",
       " 'ade': 8,\n",
       " 'adel': 50,\n",
       " 'adelaid': 30,\n",
       " 'adelin': 7,\n",
       " 'adept': 36,\n",
       " 'adequ': 148,\n",
       " 'adher': 26,\n",
       " 'adieu': 6,\n",
       " 'aditya': 26,\n",
       " 'adjac': 9,\n",
       " 'adjani': 13,\n",
       " 'adject': 18,\n",
       " 'adjust': 59,\n",
       " 'administ': 8,\n",
       " 'administr': 48,\n",
       " 'admir': 440,\n",
       " 'admiss': 45,\n",
       " 'admit': 875,\n",
       " 'admitt': 6,\n",
       " 'admonish': 5,\n",
       " 'ado': 14,\n",
       " 'adolesc': 112,\n",
       " 'adolf': 21,\n",
       " 'adolph': 14,\n",
       " 'adopt': 162,\n",
       " 'ador': 230,\n",
       " 'adorn': 12,\n",
       " 'adrenalin': 39,\n",
       " 'adrian': 55,\n",
       " 'adriana': 5,\n",
       " 'adriann': 6,\n",
       " 'adrien': 14,\n",
       " 'adrienn': 15,\n",
       " 'adrift': 9,\n",
       " 'adroit': 8,\n",
       " 'adul': 6,\n",
       " 'adult': 887,\n",
       " 'adulter': 24,\n",
       " 'adulteress': 7,\n",
       " 'adulteri': 40,\n",
       " 'adulthood': 29,\n",
       " 'adv': 17,\n",
       " 'advanc': 275,\n",
       " 'advani': 16,\n",
       " 'advantag': 172,\n",
       " 'advent': 13,\n",
       " 'adventist': 7,\n",
       " 'adventur': 773,\n",
       " 'advers': 40,\n",
       " 'adversari': 33,\n",
       " 'advert': 27,\n",
       " 'advertis': 228,\n",
       " 'advic': 262,\n",
       " 'advis': 197,\n",
       " 'advisor': 11,\n",
       " 'advoc': 31,\n",
       " 'ae': 36,\n",
       " 'aerial': 20,\n",
       " 'aerob': 7,\n",
       " 'aerodynam': 5,\n",
       " 'aesthet': 78,\n",
       " 'afar': 16,\n",
       " 'affabl': 19,\n",
       " 'affair': 419,\n",
       " 'affect': 430,\n",
       " 'affection': 31,\n",
       " 'affili': 18,\n",
       " 'affin': 21,\n",
       " 'affirm': 51,\n",
       " 'affleck': 66,\n",
       " 'afflict': 27,\n",
       " 'affluent': 25,\n",
       " 'afford': 139,\n",
       " 'affront': 7,\n",
       " 'afghan': 10,\n",
       " 'afghanistan': 36,\n",
       " 'afi': 25,\n",
       " 'aficionado': 22,\n",
       " 'afloat': 23,\n",
       " 'afoot': 8,\n",
       " 'afor': 12,\n",
       " 'aforement': 126,\n",
       " 'afoul': 13,\n",
       " 'afraid': 343,\n",
       " 'africa': 212,\n",
       " 'african': 284,\n",
       " 'afro': 26,\n",
       " 'afteral': 9,\n",
       " 'afterlif': 26,\n",
       " 'aftermath': 52,\n",
       " 'afternoon': 197,\n",
       " 'aftertast': 12,\n",
       " 'afterthought': 28,\n",
       " 'afterward': 183,\n",
       " 'afterword': 14,\n",
       " 'ag': 6,\n",
       " 'agamemnon': 10,\n",
       " 'agap': 10,\n",
       " 'agatha': 36,\n",
       " 'age': 1726,\n",
       " 'ageless': 6,\n",
       " 'agenc': 79,\n",
       " 'agenda': 86,\n",
       " 'agent': 455,\n",
       " 'ager': 7,\n",
       " 'aggi': 5,\n",
       " 'aggrav': 30,\n",
       " 'aggress': 103,\n",
       " 'aggressor': 6,\n",
       " 'aghast': 12,\n",
       " 'agi': 9,\n",
       " 'agil': 9,\n",
       " 'agin': 4,\n",
       " 'agit': 14,\n",
       " 'agitprop': 4,\n",
       " 'agn': 21,\n",
       " 'agnost': 9,\n",
       " 'ago': 1033,\n",
       " 'agon': 43,\n",
       " 'agoni': 55,\n",
       " 'agonis': 7,\n",
       " 'agre': 779,\n",
       " 'agreeabl': 11,\n",
       " 'agreement': 26,\n",
       " 'agricultur': 8,\n",
       " 'ah': 119,\n",
       " 'aha': 8,\n",
       " 'ahab': 13,\n",
       " 'ahead': 396,\n",
       " 'ahem': 21,\n",
       " 'ahh': 19,\n",
       " 'ahhh': 5,\n",
       " 'ahista': 6,\n",
       " 'ahm': 4,\n",
       " 'ahmad': 37,\n",
       " 'ahoy': 5,\n",
       " 'ai': 20,\n",
       " 'aid': 289,\n",
       " 'aida': 5,\n",
       " 'aidan': 13,\n",
       " 'aiden': 12,\n",
       " 'aiello': 34,\n",
       " 'aiken': 9,\n",
       " 'ail': 26,\n",
       " 'aileen': 11,\n",
       " 'ailment': 10,\n",
       " 'aim': 325,\n",
       " 'aime': 12,\n",
       " 'aimless': 57,\n",
       " 'aint': 7,\n",
       " 'aip': 7,\n",
       " 'air': 842,\n",
       " 'airborn': 6,\n",
       " 'aircraft': 41,\n",
       " 'airhead': 16,\n",
       " 'airless': 4,\n",
       " 'airlift': 11,\n",
       " 'airlin': 37,\n",
       " 'airplan': 106,\n",
       " 'airport': 96,\n",
       " 'airship': 8,\n",
       " 'airwav': 11,\n",
       " 'airwolf': 17,\n",
       " 'aishwarya': 9,\n",
       " 'aisl': 28,\n",
       " 'aito': 5,\n",
       " 'aj': 9,\n",
       " 'aja': 15,\n",
       " 'ajax': 9,\n",
       " 'ajay': 46,\n",
       " 'ak': 8,\n",
       " 'aka': 195,\n",
       " 'akan': 7,\n",
       " 'akbar': 4,\n",
       " 'akhra': 6,\n",
       " 'akin': 67,\n",
       " 'akira': 26,\n",
       " 'akki': 8,\n",
       " 'akroyd': 4,\n",
       " 'akshay': 125,\n",
       " 'al': 379,\n",
       " 'ala': 208,\n",
       " 'alabama': 15,\n",
       " 'aladdin': 8,\n",
       " 'alain': 30,\n",
       " 'alamo': 26,\n",
       " 'alan': 351,\n",
       " 'alar': 4,\n",
       " 'alarm': 91,\n",
       " 'alarmist': 7,\n",
       " 'alaska': 16,\n",
       " 'alaskan': 5,\n",
       " 'alastair': 13,\n",
       " 'alba': 42,\n",
       " 'albanian': 7,\n",
       " 'albeit': 157,\n",
       " 'albeniz': 5,\n",
       " 'albert': 265,\n",
       " 'alberta': 6,\n",
       " 'alberto': 17,\n",
       " 'albino': 7,\n",
       " 'albright': 6,\n",
       " 'album': 116,\n",
       " 'albuquerqu': 12,\n",
       " 'alcatraz': 12,\n",
       " 'alchemi': 6,\n",
       " 'alcohol': 225,\n",
       " 'alda': 10,\n",
       " 'alden': 7,\n",
       " 'aldo': 5,\n",
       " 'aldrin': 6,\n",
       " 'alec': 81,\n",
       " 'alecia': 5,\n",
       " 'aleck': 7,\n",
       " 'alejandro': 21,\n",
       " 'aleko': 8,\n",
       " 'alert': 103,\n",
       " 'alex': 232,\n",
       " 'alexa': 8,\n",
       " 'alexand': 122,\n",
       " 'alexandr': 67,\n",
       " 'alexandra': 40,\n",
       " 'alexi': 20,\n",
       " 'alfi': 5,\n",
       " 'alfonso': 13,\n",
       " 'alfr': 103,\n",
       " 'alfredo': 9,\n",
       " 'algi': 7,\n",
       " 'ali': 41,\n",
       " 'alia': 23,\n",
       " 'alibi': 21,\n",
       " 'alic': 199,\n",
       " 'alicia': 79,\n",
       " 'alida': 5,\n",
       " 'alien': 702,\n",
       " 'alight': 8,\n",
       " 'align': 22,\n",
       " 'alik': 154,\n",
       " 'alimoni': 10,\n",
       " 'alin': 9,\n",
       " 'alisan': 6,\n",
       " 'alison': 86,\n",
       " 'alistair': 9,\n",
       " 'aliv': 464,\n",
       " 'all': 5,\n",
       " 'alla': 5,\n",
       " 'allah': 13,\n",
       " 'allan': 40,\n",
       " 'alleg': 96,\n",
       " 'allegi': 11,\n",
       " 'allegor': 20,\n",
       " 'allegori': 34,\n",
       " 'allen': 408,\n",
       " 'allend': 16,\n",
       " 'allerg': 14,\n",
       " 'allevi': 8,\n",
       " 'alley': 79,\n",
       " 'alleyway': 6,\n",
       " 'alli': 136,\n",
       " 'allianc': 59,\n",
       " 'allig': 42,\n",
       " 'allison': 34,\n",
       " 'alloc': 5,\n",
       " 'allot': 15,\n",
       " 'allow': 1026,\n",
       " 'alloy': 6,\n",
       " 'allud': 38,\n",
       " 'allur': 55,\n",
       " 'allus': 42,\n",
       " 'allyson': 6,\n",
       " 'alma': 7,\n",
       " 'almeida': 5,\n",
       " 'almighti': 44,\n",
       " 'almodovar': 15,\n",
       " 'almost': 3139,\n",
       " 'aloi': 5,\n",
       " 'alok': 13,\n",
       " 'alon': 1066,\n",
       " 'along': 1777,\n",
       " 'alongsid': 90,\n",
       " 'alonso': 11,\n",
       " 'alonzo': 6,\n",
       " 'aloof': 26,\n",
       " 'alot': 52,\n",
       " 'aloud': 19,\n",
       " 'alp': 7,\n",
       " 'alpha': 30,\n",
       " 'alphabet': 12,\n",
       " 'alphons': 6,\n",
       " 'alreadi': 1381,\n",
       " 'alright': 185,\n",
       " 'also': 9156,\n",
       " 'alt': 11,\n",
       " 'alta': 8,\n",
       " 'altair': 9,\n",
       " 'altaira': 6,\n",
       " 'altar': 19,\n",
       " 'alter': 168,\n",
       " 'altern': 247,\n",
       " 'altho': 6,\n",
       " 'although': 2537,\n",
       " 'altitud': 8,\n",
       " 'altman': 114,\n",
       " 'altogeth': 112,\n",
       " 'altruist': 7,\n",
       " 'aluminium': 11,\n",
       " 'aluminum': 9,\n",
       " 'alumni': 13,\n",
       " 'alvarado': 8,\n",
       " 'alvin': 70,\n",
       " 'alway': 3243,\n",
       " 'alyn': 5,\n",
       " 'alyson': 7,\n",
       " 'alzheim': 7,\n",
       " 'amadeus': 8,\n",
       " 'amalgam': 16,\n",
       " 'aman': 5,\n",
       " 'amanda': 101,\n",
       " 'amass': 5,\n",
       " 'amateur': 252,\n",
       " 'amateurish': 234,\n",
       " 'amati': 5,\n",
       " 'amato': 23,\n",
       " 'amaz': 1737,\n",
       " 'amazon': 77,\n",
       " 'ambassador': 20,\n",
       " 'amber': 30,\n",
       " 'amberson': 7,\n",
       " 'ambianc': 43,\n",
       " 'ambient': 18,\n",
       " 'ambigu': 141,\n",
       " 'ambit': 118,\n",
       " 'ambiti': 129,\n",
       " 'ambival': 16,\n",
       " 'ambl': 13,\n",
       " 'ambul': 20,\n",
       " 'ambush': 26,\n",
       " 'amc': 14,\n",
       " 'amech': 15,\n",
       " 'ameli': 19,\n",
       " 'amelia': 6,\n",
       " 'amen': 13,\n",
       " 'amenabar': 10,\n",
       " 'amend': 20,\n",
       " 'america': 738,\n",
       " 'american': 2618,\n",
       " 'americana': 18,\n",
       " 'amforta': 6,\n",
       " 'ami': 120,\n",
       " 'amiabl': 33,\n",
       " 'amic': 5,\n",
       " 'amick': 15,\n",
       " 'amicus': 22,\n",
       " 'amid': 39,\n",
       " 'amidst': 53,\n",
       " 'amigo': 10,\n",
       " 'amin': 17,\n",
       " 'amish': 5,\n",
       " 'amitabh': 93,\n",
       " 'amityvill': 11,\n",
       " 'ammo': 12,\n",
       " 'ammunit': 14,\n",
       " 'amnesia': 22,\n",
       " 'amnesiac': 5,\n",
       " 'amo': 27,\n",
       " 'amok': 35,\n",
       " 'among': 783,\n",
       " 'amongst': 160,\n",
       " 'amor': 71,\n",
       " 'amount': 597,\n",
       " 'amour': 18,\n",
       " 'amp': 14,\n",
       " 'ampl': 48,\n",
       " 'ampli': 7,\n",
       " 'amplifi': 18,\n",
       " 'amput': 9,\n",
       " 'ampute': 7,\n",
       " 'amrapurkar': 8,\n",
       " 'amrish': 8,\n",
       " 'amrita': 61,\n",
       " 'amrohi': 9,\n",
       " 'amsterdam': 10,\n",
       " 'amulet': 7,\n",
       " 'amus': 742,\n",
       " 'an': 7,\n",
       " 'ana': 29,\n",
       " 'anachron': 25,\n",
       " 'anachronist': 16,\n",
       " 'anaconda': 10,\n",
       " 'anakin': 24,\n",
       " 'anal': 30,\n",
       " 'analog': 44,\n",
       " 'analys': 17,\n",
       " 'analysi': 88,\n",
       " 'analyst': 9,\n",
       " 'analyt': 9,\n",
       " 'analyz': 72,\n",
       " 'anamorph': 19,\n",
       " 'anand': 18,\n",
       " 'anansa': 11,\n",
       " 'anarch': 8,\n",
       " 'anarchi': 11,\n",
       " 'anarchist': 5,\n",
       " 'anastasia': 19,\n",
       " 'anatom': 5,\n",
       " 'anatomi': 28,\n",
       " 'anc': 11,\n",
       " 'ancestor': 43,\n",
       " 'ancestr': 5,\n",
       " 'ancestri': 16,\n",
       " 'anchor': 82,\n",
       " 'anchorman': 33,\n",
       " 'ancient': 237,\n",
       " 'and': 8,\n",
       " 'ander': 28,\n",
       " 'andersen': 5,\n",
       " 'anderson': 225,\n",
       " 'andi': 347,\n",
       " 'andr': 99,\n",
       " 'andrea': 38,\n",
       " 'andrei': 21,\n",
       " 'andress': 5,\n",
       " 'andretti': 6,\n",
       " 'andrew': 298,\n",
       " 'androgyn': 5,\n",
       " 'android': 27,\n",
       " 'andromeda': 8,\n",
       " 'anecdot': 25,\n",
       " 'anem': 9,\n",
       " 'anesthesia': 9,\n",
       " 'aneta': 10,\n",
       " 'anew': 7,\n",
       " 'ang': 44,\n",
       " 'angel': 511,\n",
       " 'angela': 85,\n",
       " 'angelica': 7,\n",
       " 'angelina': 48,\n",
       " 'angeliqu': 5,\n",
       " 'angelo': 37,\n",
       " 'angelopoulo': 19,\n",
       " 'anger': 226,\n",
       " 'angi': 55,\n",
       " 'angkor': 5,\n",
       " 'angl': 399,\n",
       " 'anglais': 6,\n",
       " 'anglo': 19,\n",
       " 'angri': 337,\n",
       " 'angrili': 12,\n",
       " 'angst': 72,\n",
       " 'angsti': 5,\n",
       " 'anguish': 55,\n",
       " 'angular': 8,\n",
       " 'angus': 12,\n",
       " 'anil': 58,\n",
       " 'anim': 2483,\n",
       " 'animatrix': 5,\n",
       " 'animatron': 14,\n",
       " 'animos': 12,\n",
       " 'anisio': 6,\n",
       " 'aniston': 43,\n",
       " 'anita': 48,\n",
       " 'anka': 4,\n",
       " 'ankl': 23,\n",
       " 'ankush': 10,\n",
       " 'ann': 542,\n",
       " 'anna': 251,\n",
       " 'annabel': 7,\n",
       " 'annabell': 6,\n",
       " 'annabella': 5,\n",
       " 'annakin': 10,\n",
       " 'annal': 13,\n",
       " 'annemari': 7,\n",
       " 'annett': 15,\n",
       " 'annex': 5,\n",
       " 'anni': 125,\n",
       " 'annihil': 18,\n",
       " 'annik': 7,\n",
       " 'anniston': 5,\n",
       " 'anniversari': 31,\n",
       " 'announc': 153,\n",
       " 'annoy': 1298,\n",
       " 'annual': 31,\n",
       " 'ano': 4,\n",
       " 'anodyn': 5,\n",
       " 'anomali': 14,\n",
       " 'anonym': 48,\n",
       " 'anorex': 12,\n",
       " 'anoth': 4326,\n",
       " 'anouska': 7,\n",
       " 'anschel': 5,\n",
       " 'anselmo': 12,\n",
       " 'answer': 626,\n",
       " 'ant': 110,\n",
       " 'antagon': 10,\n",
       " 'antagonist': 70,\n",
       " 'antarctica': 8,\n",
       " 'anthem': 26,\n",
       " 'antholog': 67,\n",
       " 'anthoni': 263,\n",
       " 'anthropologist': 17,\n",
       " 'anthropomorph': 7,\n",
       " 'anti': 480,\n",
       " 'antic': 117,\n",
       " 'antichrist': 21,\n",
       " 'anticip': 175,\n",
       " 'anticlimact': 16,\n",
       " 'antidot': 24,\n",
       " 'antihero': 13,\n",
       " 'antiqu': 39,\n",
       " 'antithesi': 16,\n",
       " 'antitrust': 7,\n",
       " 'antoin': 13,\n",
       " 'antoinett': 8,\n",
       " 'anton': 68,\n",
       " 'antonella': 5,\n",
       " 'antoni': 12,\n",
       " 'antonia': 7,\n",
       " 'antonietta': 12,\n",
       " 'antonio': 63,\n",
       " 'antonioni': 82,\n",
       " 'antonius': 5,\n",
       " 'antwerp': 19,\n",
       " 'antwon': 89,\n",
       " 'antz': 16,\n",
       " 'anu': 6,\n",
       " 'anupam': 13,\n",
       " 'anus': 7,\n",
       " 'anxieti': 48,\n",
       " 'anxious': 66,\n",
       " 'anybodi': 311,\n",
       " 'anyhoo': 6,\n",
       " 'anyhow': 60,\n",
       " 'anymor': 333,\n",
       " 'anyon': 2632,\n",
       " 'anyth': 2949,\n",
       " 'anytim': 54,\n",
       " 'anyway': 1230,\n",
       " 'anywher': 304,\n",
       " 'ao': 5,\n",
       " 'aoki': 9,\n",
       " 'ap': 10,\n",
       " 'apach': 7,\n",
       " 'apart': 995,\n",
       " 'apartheid': 40,\n",
       " 'apathet': 15,\n",
       " 'apathi': 13,\n",
       " 'apatow': 10,\n",
       " 'ape': 222,\n",
       " 'apex': 12,\n",
       " 'aphrodit': 6,\n",
       " 'aplenti': 14,\n",
       " 'aplomb': 29,\n",
       " 'apocalyps': 48,\n",
       " 'apocalypt': 50,\n",
       " 'apollo': 40,\n",
       " 'apollonia': 12,\n",
       " 'apolog': 107,\n",
       " 'apologet': 5,\n",
       " 'apologis': 15,\n",
       " 'apologist': 9,\n",
       " 'apophi': 8,\n",
       " 'appal': 187,\n",
       " 'appar': 1229,\n",
       " 'apparatus': 8,\n",
       " 'apparit': 14,\n",
       " 'appeal': 754,\n",
       " 'appear': 2568,\n",
       " 'appeas': 26,\n",
       " 'appendag': 5,\n",
       " 'appet': 8,\n",
       " 'appetit': 32,\n",
       " 'appl': 64,\n",
       " 'applaud': 102,\n",
       " 'applaus': 39,\n",
       " 'applebi': 11,\n",
       " 'appleg': 25,\n",
       " 'appli': 170,\n",
       " 'applianc': 15,\n",
       " 'applic': 30,\n",
       " 'appoint': 42,\n",
       " 'appolonia': 7,\n",
       " 'apposit': 6,\n",
       " 'apprais': 5,\n",
       " 'appreci': 852,\n",
       " 'apprehend': 11,\n",
       " 'apprehens': 14,\n",
       " 'apprentic': 34,\n",
       " 'approach': 552,\n",
       " 'appropri': 309,\n",
       " 'approv': 88,\n",
       " 'approx': 8,\n",
       " 'approxim': 50,\n",
       " 'april': 103,\n",
       " 'apron': 8,\n",
       " 'apropo': 12,\n",
       " 'apt': 79,\n",
       " 'aptitud': 9,\n",
       " 'aqua': 6,\n",
       " 'aquaman': 6,\n",
       " 'aquarium': 18,\n",
       " 'aquat': 6,\n",
       " 'ar': 21,\n",
       " 'ara': 5,\n",
       " 'arab': 103,\n",
       " 'arabella': 6,\n",
       " 'arabia': 18,\n",
       " 'arabian': 15,\n",
       " 'aragami': 5,\n",
       " 'aragorn': 23,\n",
       " 'arbitrari': 32,\n",
       " 'arbitrarili': 6,\n",
       " 'arbor': 5,\n",
       " 'arbuckl': 11,\n",
       " 'arc': 95,\n",
       " 'arcad': 10,\n",
       " 'arcan': 14,\n",
       " 'arcand': 4,\n",
       " 'arcati': 6,\n",
       " 'arch': 44,\n",
       " 'archaeolog': 20,\n",
       " 'archaeologist': 34,\n",
       " 'archaic': 15,\n",
       " 'archeologist': 6,\n",
       " 'archer': 42,\n",
       " 'archeri': 4,\n",
       " 'archetyp': 45,\n",
       " 'archi': 31,\n",
       " 'archibald': 16,\n",
       " 'architect': 40,\n",
       " 'architectur': 42,\n",
       " 'archiv': 69,\n",
       " 'arci': 6,\n",
       " 'arctic': 22,\n",
       " 'ardala': 4,\n",
       " 'ardant': 4,\n",
       " 'ardelean': 6,\n",
       " 'arden': 15,\n",
       " 'ardent': 20,\n",
       " 'ardh': 6,\n",
       " 'ardolino': 6,\n",
       " 'arduous': 15,\n",
       " 'area': 453,\n",
       " 'arena': 29,\n",
       " 'aretha': 6,\n",
       " 'argentin': 16,\n",
       " 'argentina': 24,\n",
       " 'argentinean': 5,\n",
       " 'argentinian': 13,\n",
       " 'argento': 33,\n",
       " 'argh': 8,\n",
       " 'argonn': 4,\n",
       " 'argu': 210,\n",
       " 'arguabl': 95,\n",
       " 'argument': 180,\n",
       " 'argyl': 6,\n",
       " 'ari': 8,\n",
       " 'aria': 13,\n",
       " 'ariauna': 6,\n",
       " 'arid': 8,\n",
       " 'ariel': 70,\n",
       " 'aris': 67,\n",
       " 'arisen': 5,\n",
       " 'aristid': 4,\n",
       " 'aristocraci': 13,\n",
       " 'aristocrat': 77,\n",
       " 'aristotelian': 5,\n",
       " 'arizona': 34,\n",
       " 'arjun': 18,\n",
       " 'ark': 24,\n",
       " 'arkansa': 7,\n",
       " 'arkin': 54,\n",
       " 'arkush': 4,\n",
       " 'arlen': 8,\n",
       " 'arletti': 6,\n",
       " 'arlington': 14,\n",
       " 'arliss': 5,\n",
       " 'arm': 425,\n",
       " 'armageddon': 30,\n",
       " 'armand': 16,\n",
       " 'armatur': 6,\n",
       " 'armchair': 4,\n",
       " 'armi': 474,\n",
       " 'armin': 9,\n",
       " 'armistead': 5,\n",
       " 'armitag': 5,\n",
       " 'armor': 46,\n",
       " 'armour': 16,\n",
       " 'armpit': 10,\n",
       " 'armstrong': 64,\n",
       " 'arn': 9,\n",
       " 'arnaz': 5,\n",
       " 'arnett': 4,\n",
       " 'arni': 45,\n",
       " 'arnold': 148,\n",
       " 'aro': 8,\n",
       " 'aronofski': 4,\n",
       " 'aros': 4,\n",
       " 'around': 3616,\n",
       " 'arous': 55,\n",
       " 'arquett': 56,\n",
       " 'arrang': 146,\n",
       " 'array': 47,\n",
       " 'arrest': 212,\n",
       " 'arriv': 514,\n",
       " 'arrog': 154,\n",
       " 'arrondiss': 14,\n",
       " 'arrow': 78,\n",
       " 'ars': 15,\n",
       " 'arsenal': 12,\n",
       " 'arsenic': 4,\n",
       " 'arson': 8,\n",
       " 'arsonist': 4,\n",
       " 'art': 1653,\n",
       " 'artefact': 5,\n",
       " 'artemisia': 47,\n",
       " 'arthous': 15,\n",
       " 'arthrit': 4,\n",
       " 'arthur': 374,\n",
       " 'arti': 58,\n",
       " 'articl': 67,\n",
       " 'articul': 35,\n",
       " 'artifact': 32,\n",
       " 'artific': 16,\n",
       " 'artifici': 124,\n",
       " 'artilleri': 11,\n",
       " 'artisan': 14,\n",
       " 'artist': 898,\n",
       " 'artistri': 51,\n",
       " 'artless': 7,\n",
       " 'artsi': 74,\n",
       " 'arturo': 6,\n",
       " 'artwork': 68,\n",
       " 'aruman': 5,\n",
       " 'aryan': 15,\n",
       " 'arzenta': 10,\n",
       " 'asagoro': 6,\n",
       " 'asano': 21,\n",
       " 'asap': 9,\n",
       " 'ascend': 19,\n",
       " 'ascens': 10,\n",
       " 'ascent': 4,\n",
       " 'ascertain': 11,\n",
       " 'asgard': 5,\n",
       " 'ash': 63,\n",
       " 'asham': 161,\n",
       " 'ashanti': 9,\n",
       " 'ashbi': 4,\n",
       " 'asher': 5,\n",
       " 'ashford': 8,\n",
       " 'ashleigh': 4,\n",
       " 'ashley': 89,\n",
       " 'ashor': 7,\n",
       " 'ashraf': 31,\n",
       " 'ashton': 20,\n",
       " 'ashura': 8,\n",
       " 'ashwar': 5,\n",
       " 'asia': 59,\n",
       " 'asian': 260,\n",
       " 'asid': 486,\n",
       " 'asimov': 12,\n",
       " 'asin': 15,\n",
       " 'asinin': 21,\n",
       " 'ask': 1500,\n",
       " 'askew': 8,\n",
       " 'askey': 35,\n",
       " 'asleep': 213,\n",
       " 'asner': 8,\n",
       " 'aspect': 852,\n",
       " 'asphalt': 5,\n",
       " 'aspir': 159,\n",
       " 'ass': 290,\n",
       " 'assail': 22,\n",
       " 'assan': 5,\n",
       " 'assassin': 223,\n",
       " 'assault': 132,\n",
       " 'assembl': 107,\n",
       " 'assert': 70,\n",
       " 'assess': 27,\n",
       " 'asset': 62,\n",
       " 'asshol': 13,\n",
       " 'assign': 168,\n",
       " 'assimil': 16,\n",
       " 'assist': 278,\n",
       " 'associ': 257,\n",
       " 'assort': 62,\n",
       " 'assum': 423,\n",
       " 'assumpt': 52,\n",
       " 'assur': 149,\n",
       " 'astair': 132,\n",
       " 'asthmat': 6,\n",
       " 'astin': 8,\n",
       " 'astonish': 150,\n",
       " 'astor': 21,\n",
       " 'astound': 88,\n",
       " 'astral': 9,\n",
       " 'astray': 15,\n",
       " 'astrid': 7,\n",
       " 'astro': 9,\n",
       " 'astronaut': 70,\n",
       " 'astronom': 10,\n",
       " 'astut': 37,\n",
       " 'asylum': 78,\n",
       " 'atari': 9,\n",
       " 'ate': 33,\n",
       " 'atheist': 27,\n",
       " 'athen': 11,\n",
       " 'athena': 5,\n",
       " 'athlet': 73,\n",
       " 'athletic': 9,\n",
       " 'atkin': 17,\n",
       " 'atkinson': 10,\n",
       " 'atlant': 46,\n",
       " 'atlanta': 15,\n",
       " 'atlantean': 7,\n",
       " 'atlanti': 111,\n",
       " 'atlantian': 16,\n",
       " 'atmosph': 5,\n",
       " 'atmospher': 901,\n",
       " 'atom': 47,\n",
       " 'aton': 16,\n",
       " 'atop': 28,\n",
       " 'atoz': 14,\n",
       " 'atroc': 76,\n",
       " 'atroci': 208,\n",
       " 'attach': 193,\n",
       " 'attack': 864,\n",
       " 'attain': 40,\n",
       " 'attal': 5,\n",
       " 'attempt': 1932,\n",
       " 'attenborough': 75,\n",
       " 'attend': 279,\n",
       " 'attent': 940,\n",
       " 'attest': 16,\n",
       " 'attic': 41,\n",
       " 'attila': 12,\n",
       " 'attir': 21,\n",
       " 'attitud': 327,\n",
       " 'attorney': 95,\n",
       " 'attract': 749,\n",
       " 'attribut': 88,\n",
       " 'attun': 9,\n",
       " 'atul': 11,\n",
       " 'atwil': 32,\n",
       " 'atwood': 5,\n",
       " 'atyp': 23,\n",
       " 'au': 11,\n",
       " 'aubrey': 12,\n",
       " 'auction': 19,\n",
       " 'aud': 14,\n",
       " 'audac': 14,\n",
       " 'audaci': 16,\n",
       " 'audi': 6,\n",
       " 'audiard': 25,\n",
       " 'audibl': 20,\n",
       " 'audienc': 2675,\n",
       " 'audio': 113,\n",
       " 'audit': 110,\n",
       " 'auditorium': 10,\n",
       " 'audrey': 66,\n",
       " 'audri': 7,\n",
       " 'auer': 13,\n",
       " 'augment': 12,\n",
       " 'august': 58,\n",
       " ...}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_count_dict={}\n",
    "for tag, count in zip(vocab, dist):\n",
    "    vocab_count_dict[tag]=count\n",
    "vocab_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) 랜덤포레스트 모델로 학습 후 테스트\n",
    "랜덤포레스트는 다양한 트리 모델을 만들고, 데이터를 랜덤하게 뽑은 트리에 적용한 후에 나오는 값의 평균으로 학습하는 모델. (https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train data set 으로 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# train 데이터로 학습\n",
    "random_forest = random_forest.fit(train_data_features, train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test set 에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 159 ms, sys: 211 ms, total: 370 ms\n",
      "Wall time: 50.1 s\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터의 전처리 과정\n",
    "test = pd.read_csv('testData.tsv', header=0, quoting=3, sep='\\t')\n",
    "%time clean_test_reviews = apply_by_multiprocessing(test['review'], review_to_words, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 에서는 train 데이터로부터 만들어진 vocab vector 로 벡터화 해야하므로 fit_transform 이 아니라 transform 을 사용해야한다.\n",
    "test_data_features = vectorizer.transform(clean_test_reviews)\n",
    "test_data_features = test_data_features.toarray()\n",
    "\n",
    "result = random_forest.predict(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('part1_bag-of-words.csv', index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score: 0.84660"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-gram 으로 vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=20000, min_df=1,\n",
       "        ngram_range=(2, 5), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vectorization = CountVectorizer(lowercase = True, \n",
    "                             preprocessor = None,\n",
    "                             tokenizer = None, \n",
    "                             stop_words = None,\n",
    "                             analyzer = 'word',\n",
    "                             max_features=20000,\n",
    "                             ngram_range=(2,5))\n",
    "bigram_vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1050\u001b[0m                                                        \u001b[0mmax_doc_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                                                        \u001b[0mmin_doc_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m                                                        max_features)\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_limit_features\u001b[0;34m(self, X, vocabulary, high, low, limit)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0;31m# Calculate a mask based on document frequencies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_document_frequency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m         \u001b[0mtfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhigh\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(self, axis, dtype, out)\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;31m# is in {None, -1, 0, 1}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0msum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%time bi_train_features = bigram_vectorization.fit_transform(clean_train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abbott costello',\n",
       " 'abil make',\n",
       " 'abl captur',\n",
       " 'abl enjoy',\n",
       " 'abl find',\n",
       " 'abl get',\n",
       " 'abl keep',\n",
       " 'abl make',\n",
       " 'abl see',\n",
       " 'abl sit',\n",
       " 'abl take',\n",
       " 'abl watch',\n",
       " 'abraham lincoln',\n",
       " 'abrupt end',\n",
       " 'absolut amaz',\n",
       " 'absolut aw',\n",
       " 'absolut beauti',\n",
       " 'absolut best',\n",
       " 'absolut brilliant',\n",
       " 'absolut fantast',\n",
       " 'absolut hate',\n",
       " 'absolut hilari',\n",
       " 'absolut horribl',\n",
       " 'absolut love',\n",
       " 'absolut noth',\n",
       " 'absolut one',\n",
       " 'absolut perfect',\n",
       " 'absolut reason',\n",
       " 'absolut ridicul',\n",
       " 'absolut sens',\n",
       " 'absolut stun',\n",
       " 'absolut terribl',\n",
       " 'absolut worst',\n",
       " 'abus father',\n",
       " 'abus husband',\n",
       " 'academi award',\n",
       " 'accept role',\n",
       " 'accident kill',\n",
       " 'accord dvd',\n",
       " 'accord imdb',\n",
       " 'accord movi',\n",
       " 'accur depict',\n",
       " 'accur portray',\n",
       " 'accus murder',\n",
       " 'achiev goal',\n",
       " 'acid trip',\n",
       " 'acquir tast',\n",
       " 'across board',\n",
       " 'across countri',\n",
       " 'across eye',\n",
       " 'across film',\n",
       " 'across movi',\n",
       " 'across screen',\n",
       " 'act abil',\n",
       " 'act absolut',\n",
       " 'act act',\n",
       " 'act actor',\n",
       " 'act actual',\n",
       " 'act also',\n",
       " 'act although',\n",
       " 'act amaz',\n",
       " 'act atroci',\n",
       " 'act averag',\n",
       " 'act aw',\n",
       " 'act bad',\n",
       " 'act best',\n",
       " 'act better',\n",
       " 'act bit',\n",
       " 'act brilliant',\n",
       " 'act career',\n",
       " 'act cast',\n",
       " 'act charact',\n",
       " 'act class',\n",
       " 'act convinc',\n",
       " 'act could',\n",
       " 'act decent',\n",
       " 'act dialog',\n",
       " 'act dialogu',\n",
       " 'act direct',\n",
       " 'act done',\n",
       " 'act end',\n",
       " 'act especi',\n",
       " 'act etc',\n",
       " 'act even',\n",
       " 'act ever',\n",
       " 'act everyon',\n",
       " 'act excel',\n",
       " 'act except',\n",
       " 'act extrem',\n",
       " 'act film',\n",
       " 'act fine',\n",
       " 'act first',\n",
       " 'act funni',\n",
       " 'act general',\n",
       " 'act get',\n",
       " 'act good',\n",
       " 'act great',\n",
       " 'act horribl',\n",
       " 'act howev',\n",
       " 'act incred',\n",
       " 'act job',\n",
       " 'act lame',\n",
       " 'act laughabl',\n",
       " 'act least',\n",
       " 'act lesson',\n",
       " 'act like',\n",
       " 'act littl',\n",
       " 'act look',\n",
       " 'act lot',\n",
       " 'act made',\n",
       " 'act main',\n",
       " 'act make',\n",
       " 'act mediocr',\n",
       " 'act most',\n",
       " 'act movi',\n",
       " 'act much',\n",
       " 'act music',\n",
       " 'act nice',\n",
       " 'act noth',\n",
       " 'act ok',\n",
       " 'act okay',\n",
       " 'act one',\n",
       " 'act overal',\n",
       " 'act part',\n",
       " 'act particular',\n",
       " 'act perfect',\n",
       " 'act perform',\n",
       " 'act plot',\n",
       " 'act poor',\n",
       " 'act pretti',\n",
       " 'act quit',\n",
       " 'act rang',\n",
       " 'act real',\n",
       " 'act realli',\n",
       " 'act role',\n",
       " 'act save',\n",
       " 'act scene',\n",
       " 'act script',\n",
       " 'act seem',\n",
       " 'act seen',\n",
       " 'act show',\n",
       " 'act skill',\n",
       " 'act special',\n",
       " 'act still',\n",
       " 'act stori',\n",
       " 'act stupid',\n",
       " 'act style',\n",
       " 'act suck',\n",
       " 'act superb',\n",
       " 'act talent',\n",
       " 'act terribl',\n",
       " 'act think',\n",
       " 'act though',\n",
       " 'act time',\n",
       " 'act top',\n",
       " 'act two',\n",
       " 'act violenc',\n",
       " 'act watch',\n",
       " 'act way',\n",
       " 'act weak',\n",
       " 'act well',\n",
       " 'act wonder',\n",
       " 'act wooden',\n",
       " 'act wors',\n",
       " 'act worst',\n",
       " 'act would',\n",
       " 'act write',\n",
       " 'action action',\n",
       " 'action adventur',\n",
       " 'action anim',\n",
       " 'action charact',\n",
       " 'action comedi',\n",
       " 'action drama',\n",
       " 'action even',\n",
       " 'action fan',\n",
       " 'action fight',\n",
       " 'action figur',\n",
       " 'action film',\n",
       " 'action flick',\n",
       " 'action go',\n",
       " 'action good',\n",
       " 'action great',\n",
       " 'action happen',\n",
       " 'action hero',\n",
       " 'action horror',\n",
       " 'action movi',\n",
       " 'action one',\n",
       " 'action pack',\n",
       " 'action scene',\n",
       " 'action sequenc',\n",
       " 'action star',\n",
       " 'action suspens',\n",
       " 'action take',\n",
       " 'action thriller',\n",
       " 'actor act',\n",
       " 'actor actress',\n",
       " 'actor actual',\n",
       " 'actor also',\n",
       " 'actor alway',\n",
       " 'actor appear',\n",
       " 'actor bad',\n",
       " 'actor best',\n",
       " 'actor cast',\n",
       " 'actor charact',\n",
       " 'actor come',\n",
       " 'actor could',\n",
       " 'actor deliv',\n",
       " 'actor direct',\n",
       " 'actor director',\n",
       " 'actor especi',\n",
       " 'actor even',\n",
       " 'actor ever',\n",
       " 'actor excel',\n",
       " 'actor film',\n",
       " 'actor fine',\n",
       " 'actor first',\n",
       " 'actor funni',\n",
       " 'actor gave',\n",
       " 'actor get',\n",
       " 'actor give',\n",
       " 'actor given',\n",
       " 'actor go',\n",
       " 'actor good',\n",
       " 'actor great',\n",
       " 'actor help',\n",
       " 'actor includ',\n",
       " 'actor involv',\n",
       " 'actor john',\n",
       " 'actor know',\n",
       " 'actor like',\n",
       " 'actor look',\n",
       " 'actor love',\n",
       " 'actor made',\n",
       " 'actor make',\n",
       " 'actor mani',\n",
       " 'actor movi',\n",
       " 'actor much',\n",
       " 'actor must',\n",
       " 'actor name',\n",
       " 'actor never',\n",
       " 'actor one',\n",
       " 'actor oscar',\n",
       " 'actor perform',\n",
       " 'actor play',\n",
       " 'actor portray',\n",
       " 'actor pretti',\n",
       " 'actor probabl',\n",
       " 'actor put',\n",
       " 'actor realli',\n",
       " 'actor role',\n",
       " 'actor say',\n",
       " 'actor seem',\n",
       " 'actor seen',\n",
       " 'actor show',\n",
       " 'actor speak',\n",
       " 'actor stori',\n",
       " 'actor take',\n",
       " 'actor talent',\n",
       " 'actor think',\n",
       " 'actor time',\n",
       " 'actor tri',\n",
       " 'actor wast',\n",
       " 'actor well',\n",
       " 'actor whose',\n",
       " 'actor work',\n",
       " 'actor world',\n",
       " 'actor would',\n",
       " 'actor writer',\n",
       " 'actress ever',\n",
       " 'actress film',\n",
       " 'actress like',\n",
       " 'actress make',\n",
       " 'actress movi',\n",
       " 'actress one',\n",
       " 'actress play',\n",
       " 'actual act',\n",
       " 'actual bad',\n",
       " 'actual believ',\n",
       " 'actual better',\n",
       " 'actual care',\n",
       " 'actual charact',\n",
       " 'actual come',\n",
       " 'actual end',\n",
       " 'actual enjoy',\n",
       " 'actual event',\n",
       " 'actual exist',\n",
       " 'actual fact',\n",
       " 'actual feel',\n",
       " 'actual felt',\n",
       " 'actual film',\n",
       " 'actual first',\n",
       " 'actual found',\n",
       " 'actual funni',\n",
       " 'actual get',\n",
       " 'actual go',\n",
       " 'actual good',\n",
       " 'actual got',\n",
       " 'actual happen',\n",
       " 'actual interest',\n",
       " 'actual kill',\n",
       " 'actual kind',\n",
       " 'actual know',\n",
       " 'actual like',\n",
       " 'actual look',\n",
       " 'actual lot',\n",
       " 'actual love',\n",
       " 'actual made',\n",
       " 'actual make',\n",
       " 'actual manag',\n",
       " 'actual movi',\n",
       " 'actual much',\n",
       " 'actual murder',\n",
       " 'actual one',\n",
       " 'actual paid',\n",
       " 'actual peopl',\n",
       " 'actual play',\n",
       " 'actual plot',\n",
       " 'actual pretti',\n",
       " 'actual put',\n",
       " 'actual quit',\n",
       " 'actual read',\n",
       " 'actual realli',\n",
       " 'actual sat',\n",
       " 'actual saw',\n",
       " 'actual say',\n",
       " 'actual scare',\n",
       " 'actual see',\n",
       " 'actual seem',\n",
       " 'actual seen',\n",
       " 'actual shot',\n",
       " 'actual show',\n",
       " 'actual start',\n",
       " 'actual stori',\n",
       " 'actual take',\n",
       " 'actual tell',\n",
       " 'actual think',\n",
       " 'actual thought',\n",
       " 'actual took',\n",
       " 'actual tri',\n",
       " 'actual turn',\n",
       " 'actual use',\n",
       " 'actual want',\n",
       " 'actual watch',\n",
       " 'actual went',\n",
       " 'actual work',\n",
       " 'actual would',\n",
       " 'ad lib',\n",
       " 'adam burt',\n",
       " 'adam sandler',\n",
       " 'adam west',\n",
       " 'adapt book',\n",
       " 'adapt classic',\n",
       " 'adapt novel',\n",
       " 'adapt screen',\n",
       " 'adapt stori',\n",
       " 'add anoth',\n",
       " 'add anyth',\n",
       " 'add extra',\n",
       " 'add insult',\n",
       " 'add littl',\n",
       " 'add movi',\n",
       " 'add much',\n",
       " 'add noth',\n",
       " 'add one',\n",
       " 'add someth',\n",
       " 'admit film',\n",
       " 'admit first',\n",
       " 'admit like',\n",
       " 'admit one',\n",
       " 'ador movi',\n",
       " 'adult audienc',\n",
       " 'adult children',\n",
       " 'adult film',\n",
       " 'adult kid',\n",
       " 'adult movi',\n",
       " 'advanc screen',\n",
       " 'adventur film',\n",
       " 'adventur movi',\n",
       " 'advic watch',\n",
       " 'advis watch',\n",
       " 'african american',\n",
       " 'afro american',\n",
       " 'agatha christi',\n",
       " 'age differ',\n",
       " 'age film',\n",
       " 'age group',\n",
       " 'age man',\n",
       " 'age movi',\n",
       " 'age old',\n",
       " 'age stori',\n",
       " 'age well',\n",
       " 'age woman',\n",
       " 'age would',\n",
       " 'ago like',\n",
       " 'ago saw',\n",
       " 'ago still',\n",
       " 'ago watch',\n",
       " 'agre comment',\n",
       " 'agre film',\n",
       " 'agre movi',\n",
       " 'agre one',\n",
       " 'agre review',\n",
       " 'ahead make',\n",
       " 'ahead time',\n",
       " 'ahead watch',\n",
       " 'air forc',\n",
       " 'ajay devgan',\n",
       " 'akshay khanna',\n",
       " 'akshay kumar',\n",
       " 'al gore',\n",
       " 'al pacino',\n",
       " 'alan arkin',\n",
       " 'alan curti',\n",
       " 'alan feinston',\n",
       " 'alan hale',\n",
       " 'alan johnson',\n",
       " 'albert einstein',\n",
       " 'albert finney',\n",
       " 'alec baldwin',\n",
       " 'alec guin',\n",
       " 'alexand korda',\n",
       " 'alexandra staden',\n",
       " 'alexi smith',\n",
       " 'alfr hitchcock',\n",
       " 'alfr woodard',\n",
       " 'ali khan',\n",
       " 'alic bradi',\n",
       " 'alic cooper',\n",
       " 'alic krige',\n",
       " 'alic wonderland',\n",
       " 'alicia silverston',\n",
       " 'alien peopl',\n",
       " 'alien thing',\n",
       " 'allen poe',\n",
       " 'alli sheedi',\n",
       " 'allow audienc',\n",
       " 'allow film',\n",
       " 'allow go',\n",
       " 'allow us',\n",
       " 'allow viewer',\n",
       " 'almost alway',\n",
       " 'almost anyth',\n",
       " 'almost bad',\n",
       " 'almost certain',\n",
       " 'almost comic',\n",
       " 'almost complet',\n",
       " 'almost entir',\n",
       " 'almost everi',\n",
       " 'almost everyon',\n",
       " 'almost everyth',\n",
       " 'almost exact',\n",
       " 'almost feel',\n",
       " 'almost fell',\n",
       " 'almost film',\n",
       " 'almost get',\n",
       " 'almost good',\n",
       " 'almost hour',\n",
       " 'almost immedi',\n",
       " 'almost imposs',\n",
       " 'almost like',\n",
       " 'almost made',\n",
       " 'almost make',\n",
       " 'almost movi',\n",
       " 'almost much',\n",
       " 'almost never',\n",
       " 'almost none',\n",
       " 'almost noth',\n",
       " 'almost pain',\n",
       " 'almost perfect',\n",
       " 'almost seem',\n",
       " 'almost two',\n",
       " 'almost unbear',\n",
       " 'almost year',\n",
       " 'alon dark',\n",
       " 'alon film',\n",
       " 'alon make',\n",
       " 'alon movi',\n",
       " 'alon one',\n",
       " 'alon worth',\n",
       " 'alon would',\n",
       " 'along come',\n",
       " 'along like',\n",
       " 'along line',\n",
       " 'along movi',\n",
       " 'along nice',\n",
       " 'along ride',\n",
       " 'along stori',\n",
       " 'along two',\n",
       " 'along way',\n",
       " 'along well',\n",
       " 'alreadi dead',\n",
       " 'alreadi done',\n",
       " 'alreadi knew',\n",
       " 'alreadi know',\n",
       " 'alreadi made',\n",
       " 'alreadi mention',\n",
       " 'alreadi said',\n",
       " 'alreadi seen',\n",
       " 'also act',\n",
       " 'also actor',\n",
       " 'also add',\n",
       " 'also amaz',\n",
       " 'also amus',\n",
       " 'also annoy',\n",
       " 'also anoth',\n",
       " 'also appear',\n",
       " 'also attempt',\n",
       " 'also bad',\n",
       " 'also beauti',\n",
       " 'also becom',\n",
       " 'also believ',\n",
       " 'also best',\n",
       " 'also better',\n",
       " 'also bit',\n",
       " 'also bring',\n",
       " 'also cast',\n",
       " 'also charact',\n",
       " 'also clear',\n",
       " 'also come',\n",
       " 'also complet',\n",
       " 'also contain',\n",
       " 'also deal',\n",
       " 'also direct',\n",
       " 'also director',\n",
       " 'also done',\n",
       " 'also effect',\n",
       " 'also end',\n",
       " 'also enjoy',\n",
       " 'also excel',\n",
       " 'also extrem',\n",
       " 'also fact',\n",
       " 'also fail',\n",
       " 'also fair',\n",
       " 'also featur',\n",
       " 'also feel',\n",
       " 'also felt',\n",
       " 'also film',\n",
       " 'also find',\n",
       " 'also fine',\n",
       " 'also first',\n",
       " 'also found',\n",
       " 'also fun',\n",
       " 'also funni',\n",
       " 'also gave',\n",
       " 'also get',\n",
       " 'also give',\n",
       " 'also go',\n",
       " 'also good',\n",
       " 'also got',\n",
       " 'also great',\n",
       " 'also happen',\n",
       " 'also hard',\n",
       " 'also hate',\n",
       " 'also heard',\n",
       " 'also help',\n",
       " 'also high',\n",
       " 'also hope',\n",
       " 'also impress',\n",
       " 'also includ',\n",
       " 'also incred',\n",
       " 'also interest',\n",
       " 'also know',\n",
       " 'also known',\n",
       " 'also lack',\n",
       " 'also like',\n",
       " 'also littl',\n",
       " 'also look',\n",
       " 'also lot',\n",
       " 'also love',\n",
       " 'also made',\n",
       " 'also make',\n",
       " 'also manag',\n",
       " 'also mani',\n",
       " 'also meet',\n",
       " 'also mention',\n",
       " 'also movi',\n",
       " 'also much',\n",
       " 'also must',\n",
       " 'also need',\n",
       " 'also never',\n",
       " 'also nice',\n",
       " 'also note',\n",
       " 'also notic',\n",
       " 'also one',\n",
       " 'also part',\n",
       " 'also peopl',\n",
       " 'also play',\n",
       " 'also point',\n",
       " 'also poor',\n",
       " 'also present',\n",
       " 'also pretti',\n",
       " 'also provid',\n",
       " 'also put',\n",
       " 'also quit',\n",
       " 'also rather',\n",
       " 'also read',\n",
       " 'also realli',\n",
       " 'also reason',\n",
       " 'also recommend',\n",
       " 'also rememb',\n",
       " 'also respons',\n",
       " 'also saw',\n",
       " 'also say',\n",
       " 'also scene',\n",
       " 'also see',\n",
       " 'also seem',\n",
       " 'also seen',\n",
       " 'also serv',\n",
       " 'also set',\n",
       " 'also show',\n",
       " 'also someth',\n",
       " 'also star',\n",
       " 'also stori',\n",
       " 'also strong',\n",
       " 'also suffer',\n",
       " 'also superb',\n",
       " 'also surpris',\n",
       " 'also take',\n",
       " 'also think',\n",
       " 'also thought',\n",
       " 'also total',\n",
       " 'also touch',\n",
       " 'also tri',\n",
       " 'also true',\n",
       " 'also turn',\n",
       " 'also two',\n",
       " 'also use',\n",
       " 'also want',\n",
       " 'also watch',\n",
       " 'also way',\n",
       " 'also well',\n",
       " 'also wonder',\n",
       " 'also work',\n",
       " 'also worth',\n",
       " 'also would',\n",
       " 'also wrote',\n",
       " 'alter ego',\n",
       " 'altern realiti',\n",
       " 'altern titl',\n",
       " 'although act',\n",
       " 'although admit',\n",
       " 'although could',\n",
       " 'although end',\n",
       " 'although film',\n",
       " 'although know',\n",
       " 'although like',\n",
       " 'although littl',\n",
       " 'although mani',\n",
       " 'although may',\n",
       " 'although movi',\n",
       " 'although much',\n",
       " 'although never',\n",
       " 'although one',\n",
       " 'although quit',\n",
       " 'although realli',\n",
       " 'although see',\n",
       " 'although seem',\n",
       " 'although still',\n",
       " 'although stori',\n",
       " 'although think',\n",
       " 'although time',\n",
       " 'although would',\n",
       " 'alvin straight',\n",
       " 'alway come',\n",
       " 'alway enjoy',\n",
       " 'alway entertain',\n",
       " 'alway fan',\n",
       " 'alway favorit',\n",
       " 'alway felt',\n",
       " 'alway find',\n",
       " 'alway found',\n",
       " 'alway fun',\n",
       " 'alway funni',\n",
       " 'alway get',\n",
       " 'alway give',\n",
       " 'alway go',\n",
       " 'alway good',\n",
       " 'alway great',\n",
       " 'alway interest',\n",
       " 'alway keep',\n",
       " 'alway like',\n",
       " 'alway look',\n",
       " 'alway love',\n",
       " 'alway make',\n",
       " 'alway manag',\n",
       " 'alway nice',\n",
       " 'alway one',\n",
       " 'alway play',\n",
       " 'alway pleasur',\n",
       " 'alway reliabl',\n",
       " 'alway rememb',\n",
       " 'alway right',\n",
       " 'alway ring',\n",
       " 'alway say',\n",
       " 'alway seem',\n",
       " 'alway someth',\n",
       " 'alway think',\n",
       " 'alway thought',\n",
       " 'alway tri',\n",
       " 'alway want',\n",
       " 'alway watch',\n",
       " 'alway wear',\n",
       " 'alway wonder',\n",
       " 'alway work',\n",
       " 'alway worth',\n",
       " 'amanda peet',\n",
       " 'amaz act',\n",
       " 'amaz actor',\n",
       " 'amaz bad',\n",
       " 'amaz cast',\n",
       " 'amaz even',\n",
       " 'amaz film',\n",
       " 'amaz job',\n",
       " 'amaz mani',\n",
       " 'amaz movi',\n",
       " 'amaz one',\n",
       " 'amaz perform',\n",
       " 'amaz see',\n",
       " 'amaz show',\n",
       " 'amaz stori',\n",
       " 'amaz thing',\n",
       " 'amaz watch',\n",
       " 'amaz well',\n",
       " 'amazon com',\n",
       " 'american accent',\n",
       " 'american actor',\n",
       " 'american audienc',\n",
       " 'american beauti',\n",
       " 'american cinema',\n",
       " 'american cultur',\n",
       " 'american dream',\n",
       " 'american famili',\n",
       " 'american film',\n",
       " 'american girl',\n",
       " 'american gothic',\n",
       " 'american histori',\n",
       " 'american indian',\n",
       " 'american movi',\n",
       " 'american pari',\n",
       " 'american peopl',\n",
       " 'american pie',\n",
       " 'american psycho',\n",
       " 'american societi',\n",
       " 'american soldier',\n",
       " 'american town',\n",
       " 'american tv',\n",
       " 'american version',\n",
       " 'american werewolf',\n",
       " 'american woman',\n",
       " 'ami adam',\n",
       " 'amitabh bachchan',\n",
       " 'among best',\n",
       " 'among charact',\n",
       " 'among mani',\n",
       " 'among other',\n",
       " 'among thing',\n",
       " 'among us',\n",
       " 'among worst',\n",
       " 'amount blood',\n",
       " 'amount money',\n",
       " 'amount time',\n",
       " 'amrita rao',\n",
       " 'amus moment',\n",
       " 'amus park',\n",
       " 'anchor aweigh',\n",
       " 'andi goldsworthi',\n",
       " 'andi hardi',\n",
       " 'andi warhol',\n",
       " 'ang lee',\n",
       " 'angela lansburi',\n",
       " 'angelina joli',\n",
       " 'angi dickinson',\n",
       " 'anil kapoor',\n",
       " 'anim also',\n",
       " 'anim anim',\n",
       " 'anim charact',\n",
       " 'anim fan',\n",
       " 'anim featur',\n",
       " 'anim film',\n",
       " 'anim great',\n",
       " 'anim hous',\n",
       " 'anim like',\n",
       " 'anim live',\n",
       " 'anim look',\n",
       " 'anim lover',\n",
       " 'anim make',\n",
       " 'anim movi',\n",
       " 'anim one',\n",
       " 'anim seri',\n",
       " 'anim short',\n",
       " 'anim show',\n",
       " 'anim style',\n",
       " 'anim version',\n",
       " 'anim well',\n",
       " 'ann andi',\n",
       " 'ann franci',\n",
       " 'ann mari',\n",
       " 'ann moss',\n",
       " 'ann reid',\n",
       " 'anna christi',\n",
       " 'anna fari',\n",
       " 'anna paquin',\n",
       " 'anni hall',\n",
       " 'annoy charact',\n",
       " 'annoy film',\n",
       " 'annoy movi',\n",
       " 'annoy time',\n",
       " 'annoy voic',\n",
       " 'anoth actor',\n",
       " 'anoth aspect',\n",
       " 'anoth bad',\n",
       " 'anoth big',\n",
       " 'anoth chanc',\n",
       " 'anoth charact',\n",
       " 'anoth classic',\n",
       " 'anoth comment',\n",
       " 'anoth coupl',\n",
       " 'anoth day',\n",
       " 'anoth exampl',\n",
       " 'anoth film',\n",
       " 'anoth fine',\n",
       " 'anoth girl',\n",
       " 'anoth good',\n",
       " 'anoth great',\n",
       " 'anoth guy',\n",
       " 'anoth human',\n",
       " 'anoth level',\n",
       " 'anoth major',\n",
       " 'anoth man',\n",
       " 'anoth minut',\n",
       " 'anoth movi',\n",
       " 'anoth one',\n",
       " 'anoth person',\n",
       " 'anoth planet',\n",
       " 'anoth point',\n",
       " 'anoth problem',\n",
       " 'anoth reason',\n",
       " 'anoth review',\n",
       " 'anoth scene',\n",
       " 'anoth show',\n",
       " 'anoth stori',\n",
       " 'anoth thing',\n",
       " 'anoth time',\n",
       " 'anoth user',\n",
       " 'anoth way',\n",
       " 'anoth woman',\n",
       " 'anoth world',\n",
       " 'anoth year',\n",
       " 'answer phone',\n",
       " 'answer question',\n",
       " 'anthoni hopkin',\n",
       " 'anthoni mann',\n",
       " 'anthoni quinn',\n",
       " 'anti american',\n",
       " 'anti christ',\n",
       " 'anti climat',\n",
       " 'anti establish',\n",
       " 'anti hero',\n",
       " 'anti semit',\n",
       " 'anti social',\n",
       " 'anti war',\n",
       " 'anton newcomb',\n",
       " 'antwon fisher',\n",
       " 'anybodi els',\n",
       " 'anyon actual',\n",
       " 'anyon age',\n",
       " 'anyon care',\n",
       " 'anyon could',\n",
       " 'anyon els',\n",
       " 'anyon enjoy',\n",
       " 'anyon even',\n",
       " 'anyon ever',\n",
       " 'anyon familiar',\n",
       " 'anyon find',\n",
       " 'anyon get',\n",
       " 'anyon give',\n",
       " 'anyon interest',\n",
       " 'anyon involv',\n",
       " 'anyon know',\n",
       " 'anyon like',\n",
       " 'anyon look',\n",
       " 'anyon love',\n",
       " 'anyon make',\n",
       " 'anyon read',\n",
       " 'anyon realli',\n",
       " 'anyon rememb',\n",
       " 'anyon say',\n",
       " 'anyon see',\n",
       " 'anyon seen',\n",
       " 'anyon tell',\n",
       " 'anyon think',\n",
       " 'anyon want',\n",
       " 'anyon watch',\n",
       " 'anyon would',\n",
       " 'anyth away',\n",
       " 'anyth bad',\n",
       " 'anyth better',\n",
       " 'anyth could',\n",
       " 'anyth els',\n",
       " 'anyth even',\n",
       " 'anyth ever',\n",
       " 'anyth except',\n",
       " 'anyth film',\n",
       " 'anyth get',\n",
       " 'anyth go',\n",
       " 'anyth good',\n",
       " 'anyth happen',\n",
       " 'anyth interest',\n",
       " 'anyth like',\n",
       " 'anyth make',\n",
       " 'anyth might',\n",
       " 'anyth movi',\n",
       " 'anyth new',\n",
       " 'anyth one',\n",
       " 'anyth plot',\n",
       " 'anyth realli',\n",
       " 'anyth remot',\n",
       " 'anyth say',\n",
       " 'anyth seen',\n",
       " 'anyth special',\n",
       " 'anyth stori',\n",
       " 'anyth want',\n",
       " 'anyth worth',\n",
       " 'anyth would',\n",
       " 'anyth wrong',\n",
       " 'anyway film',\n",
       " 'anyway great',\n",
       " 'anyway like',\n",
       " 'anyway movi',\n",
       " 'anyway one',\n",
       " 'anyway see',\n",
       " 'anywher els',\n",
       " 'anywher near',\n",
       " 'apart build',\n",
       " 'apart film',\n",
       " 'apart one',\n",
       " 'ape man',\n",
       " 'appar film',\n",
       " 'appar one',\n",
       " 'appar reason',\n",
       " 'appeal film',\n",
       " 'appear disappear',\n",
       " 'appear film',\n",
       " 'appear first',\n",
       " 'appear like',\n",
       " 'appear mani',\n",
       " 'appear movi',\n",
       " 'appear nowher',\n",
       " 'appear one',\n",
       " 'appear screen',\n",
       " 'appear show',\n",
       " 'appreci film',\n",
       " 'appreci good',\n",
       " 'appreci movi',\n",
       " 'approach film',\n",
       " 'april fool',\n",
       " 'archiv footag',\n",
       " 'arm forc',\n",
       " 'arm leg',\n",
       " 'arm man',\n",
       " 'arnold schwarzenegg',\n",
       " 'around also',\n",
       " 'around bit',\n",
       " 'around charact',\n",
       " 'around corner',\n",
       " 'around countri',\n",
       " 'around even',\n",
       " 'around film',\n",
       " 'around get',\n",
       " 'around hous',\n",
       " 'around kill',\n",
       " 'around like',\n",
       " 'around look',\n",
       " 'around lot',\n",
       " 'around make',\n",
       " 'around minut',\n",
       " 'around movi',\n",
       " 'around one',\n",
       " 'around peopl',\n",
       " 'around room',\n",
       " 'around say',\n",
       " 'around time',\n",
       " 'around town',\n",
       " 'around tri',\n",
       " 'around two',\n",
       " 'around us',\n",
       " 'around watch',\n",
       " 'around wood',\n",
       " 'around world',\n",
       " 'around year',\n",
       " 'arrang marriag',\n",
       " 'arrest develop',\n",
       " 'art action',\n",
       " 'art cinema',\n",
       " 'art deco',\n",
       " 'art direct',\n",
       " 'art director',\n",
       " 'art film',\n",
       " 'art form',\n",
       " 'art galleri',\n",
       " ...]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vectorization.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-9c7503604e1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# train 데이터로 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mforest_bigram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforest_bigram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbi_train_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 333\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_bigram = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# train 데이터로 학습\n",
    "forest_bigram = forest_bigram.fit(bi_train_features, train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
