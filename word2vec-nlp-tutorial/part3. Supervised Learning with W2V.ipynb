{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n",
      "(25000, 2)\n",
      "(50000, 2)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('labeledTrainData.tsv', header=0, sep='\\t', quoting=3)\n",
    "test = pd.read_csv('testData.tsv', header=0, sep='\\t', quoting=3)\n",
    "unlabeled_train = pd.read_csv('unlabeledTrainData.tsv', header=0, sep='\\t', quoting=3)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(unlabeled_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"300features_40minwords_10context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Word2VecKeyedVectors.load_word2vec_format of <class 'gensim.models.keyedvectors.Word2VecKeyedVectors'>>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.load_word2vec_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.index2word == model.wv.index2entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyunkyungbae/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['doctor'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review 의 평균 벡터 구하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word 로 구성된 리스트를 넣었을 때, word 의 vector 평균을 구하는 함수 (입력값: 하나의 sentence)\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    featureVec = np.zeros((num_features,), dtype='float32')\n",
    "    nwords = 0\n",
    "    vector_words = set(model.wv.index2word)\n",
    "    for word in words:\n",
    "        if word in vector_words:\n",
    "            nwords = nwords+1\n",
    "            featureVec = np.add(featureVec, model[word])\n",
    "    featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence 로 구성된 리스트를 넣었을 때, sentence 의 벡터 평균을 구하는 함수\n",
    "def reviewFeatureVec(reviews, model, num_features):\n",
    "    reviewFeatureVec = np.zeros((len(reviews),num_features))\n",
    "    counter = 0\n",
    "    for review in reviews:\n",
    "        if counter%1000==0:\n",
    "            print(\"Review %d of %d\" % (counter, len(reviews)))\n",
    "        reviewFeatureVec[int(counter)] =  makeFeatureVec(review, model, num_features)\n",
    "        counter = counter+1\n",
    "    return reviewFeatureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 300\n",
    "min_word_count = 40\n",
    "num_workers = 4\n",
    "context = 10\n",
    "downsampling = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle_w2v import KaggleWord2VecUtility\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# 멀티스레드로 4개의 워커를 사용해 처리한다.\n",
    "def getCleanReviews(reviews):\n",
    "    clean_reviews = []\n",
    "    clean_reviews = KaggleWord2VecUtility.apply_by_multiprocessing(\\\n",
    "        reviews[\"review\"], KaggleWord2VecUtility.review_to_wordlist,\\\n",
    "        workers=4)\n",
    "    return clean_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyunkyungbae/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 100 of 25000\n",
      "Review 200 of 25000\n",
      "Review 300 of 25000\n",
      "Review 400 of 25000\n",
      "Review 500 of 25000\n",
      "Review 600 of 25000\n",
      "Review 700 of 25000\n",
      "Review 800 of 25000\n",
      "Review 900 of 25000\n",
      "Review 1000 of 25000\n",
      "Review 1100 of 25000\n",
      "Review 1200 of 25000\n",
      "Review 1300 of 25000\n",
      "Review 1400 of 25000\n",
      "Review 1500 of 25000\n",
      "Review 1600 of 25000\n",
      "Review 1700 of 25000\n",
      "Review 1800 of 25000\n",
      "Review 1900 of 25000\n",
      "Review 2000 of 25000\n",
      "Review 2100 of 25000\n",
      "Review 2200 of 25000\n",
      "Review 2300 of 25000\n",
      "Review 2400 of 25000\n",
      "Review 2500 of 25000\n",
      "Review 2600 of 25000\n",
      "Review 2700 of 25000\n",
      "Review 2800 of 25000\n",
      "Review 2900 of 25000\n",
      "Review 3000 of 25000\n",
      "Review 3100 of 25000\n",
      "Review 3200 of 25000\n",
      "Review 3300 of 25000\n",
      "Review 3400 of 25000\n",
      "Review 3500 of 25000\n",
      "Review 3600 of 25000\n",
      "Review 3700 of 25000\n",
      "Review 3800 of 25000\n",
      "Review 3900 of 25000\n",
      "Review 4000 of 25000\n",
      "Review 4100 of 25000\n",
      "Review 4200 of 25000\n",
      "Review 4300 of 25000\n",
      "Review 4400 of 25000\n",
      "Review 4500 of 25000\n",
      "Review 4600 of 25000\n",
      "Review 4700 of 25000\n",
      "Review 4800 of 25000\n",
      "Review 4900 of 25000\n",
      "Review 5000 of 25000\n",
      "Review 5100 of 25000\n",
      "Review 5200 of 25000\n",
      "Review 5300 of 25000\n",
      "Review 5400 of 25000\n",
      "Review 5500 of 25000\n",
      "Review 5600 of 25000\n",
      "Review 5700 of 25000\n",
      "Review 5800 of 25000\n",
      "Review 5900 of 25000\n",
      "Review 6000 of 25000\n",
      "Review 6100 of 25000\n",
      "Review 6200 of 25000\n",
      "Review 6300 of 25000\n",
      "Review 6400 of 25000\n",
      "Review 6500 of 25000\n",
      "Review 6600 of 25000\n",
      "Review 6700 of 25000\n",
      "Review 6800 of 25000\n",
      "Review 6900 of 25000\n",
      "Review 7000 of 25000\n",
      "Review 7100 of 25000\n",
      "Review 7200 of 25000\n",
      "Review 7300 of 25000\n",
      "Review 7400 of 25000\n",
      "Review 7500 of 25000\n",
      "Review 7600 of 25000\n",
      "Review 7700 of 25000\n",
      "Review 7800 of 25000\n",
      "Review 7900 of 25000\n",
      "Review 8000 of 25000\n",
      "Review 8100 of 25000\n",
      "Review 8200 of 25000\n",
      "Review 8300 of 25000\n",
      "Review 8400 of 25000\n",
      "Review 8500 of 25000\n",
      "Review 8600 of 25000\n",
      "Review 8700 of 25000\n",
      "Review 8800 of 25000\n",
      "Review 8900 of 25000\n",
      "Review 9000 of 25000\n",
      "Review 9100 of 25000\n",
      "Review 9200 of 25000\n",
      "Review 9300 of 25000\n",
      "Review 9400 of 25000\n",
      "Review 9500 of 25000\n",
      "Review 9600 of 25000\n",
      "Review 9700 of 25000\n",
      "Review 9800 of 25000\n",
      "Review 9900 of 25000\n",
      "Review 10000 of 25000\n",
      "Review 10100 of 25000\n",
      "Review 10200 of 25000\n",
      "Review 10300 of 25000\n",
      "Review 10400 of 25000\n",
      "Review 10500 of 25000\n",
      "Review 10600 of 25000\n",
      "Review 10700 of 25000\n",
      "Review 10800 of 25000\n",
      "Review 10900 of 25000\n",
      "Review 11000 of 25000\n",
      "Review 11100 of 25000\n",
      "Review 11200 of 25000\n",
      "Review 11300 of 25000\n",
      "Review 11400 of 25000\n",
      "Review 11500 of 25000\n",
      "Review 11600 of 25000\n",
      "Review 11700 of 25000\n",
      "Review 11800 of 25000\n",
      "Review 11900 of 25000\n",
      "Review 12000 of 25000\n",
      "Review 12100 of 25000\n",
      "Review 12200 of 25000\n",
      "Review 12300 of 25000\n",
      "Review 12400 of 25000\n",
      "Review 12500 of 25000\n",
      "Review 12600 of 25000\n",
      "Review 12700 of 25000\n",
      "Review 12800 of 25000\n",
      "Review 12900 of 25000\n",
      "Review 13000 of 25000\n",
      "Review 13100 of 25000\n",
      "Review 13200 of 25000\n",
      "Review 13300 of 25000\n",
      "Review 13400 of 25000\n",
      "Review 13500 of 25000\n",
      "Review 13600 of 25000\n",
      "Review 13700 of 25000\n",
      "Review 13800 of 25000\n",
      "Review 13900 of 25000\n",
      "Review 14000 of 25000\n",
      "Review 14100 of 25000\n",
      "Review 14200 of 25000\n",
      "Review 14300 of 25000\n",
      "Review 14400 of 25000\n",
      "Review 14500 of 25000\n",
      "Review 14600 of 25000\n",
      "Review 14700 of 25000\n",
      "Review 14800 of 25000\n",
      "Review 14900 of 25000\n",
      "Review 15000 of 25000\n",
      "Review 15100 of 25000\n",
      "Review 15200 of 25000\n",
      "Review 15300 of 25000\n",
      "Review 15400 of 25000\n",
      "Review 15500 of 25000\n",
      "Review 15600 of 25000\n",
      "Review 15700 of 25000\n",
      "Review 15800 of 25000\n",
      "Review 15900 of 25000\n",
      "Review 16000 of 25000\n",
      "Review 16100 of 25000\n",
      "Review 16200 of 25000\n",
      "Review 16300 of 25000\n",
      "Review 16400 of 25000\n",
      "Review 16500 of 25000\n",
      "Review 16600 of 25000\n",
      "Review 16700 of 25000\n",
      "Review 16800 of 25000\n",
      "Review 16900 of 25000\n",
      "Review 17000 of 25000\n",
      "Review 17100 of 25000\n",
      "Review 17200 of 25000\n",
      "Review 17300 of 25000\n",
      "Review 17400 of 25000\n",
      "Review 17500 of 25000\n",
      "Review 17600 of 25000\n",
      "Review 17700 of 25000\n",
      "Review 17800 of 25000\n",
      "Review 17900 of 25000\n",
      "Review 18000 of 25000\n",
      "Review 18100 of 25000\n",
      "Review 18200 of 25000\n",
      "Review 18300 of 25000\n",
      "Review 18400 of 25000\n",
      "Review 18500 of 25000\n",
      "Review 18600 of 25000\n",
      "Review 18700 of 25000\n",
      "Review 18800 of 25000\n",
      "Review 18900 of 25000\n",
      "Review 19000 of 25000\n",
      "Review 19100 of 25000\n",
      "Review 19200 of 25000\n",
      "Review 19300 of 25000\n",
      "Review 19400 of 25000\n",
      "Review 19500 of 25000\n",
      "Review 19600 of 25000\n",
      "Review 19700 of 25000\n",
      "Review 19800 of 25000\n",
      "Review 19900 of 25000\n",
      "Review 20000 of 25000\n",
      "Review 20100 of 25000\n",
      "Review 20200 of 25000\n",
      "Review 20300 of 25000\n",
      "Review 20400 of 25000\n",
      "Review 20500 of 25000\n",
      "Review 20600 of 25000\n",
      "Review 20700 of 25000\n",
      "Review 20800 of 25000\n",
      "Review 20900 of 25000\n",
      "Review 21000 of 25000\n",
      "Review 21100 of 25000\n",
      "Review 21200 of 25000\n",
      "Review 21300 of 25000\n",
      "Review 21400 of 25000\n",
      "Review 21500 of 25000\n",
      "Review 21600 of 25000\n",
      "Review 21700 of 25000\n",
      "Review 21800 of 25000\n",
      "Review 21900 of 25000\n",
      "Review 22000 of 25000\n",
      "Review 22100 of 25000\n",
      "Review 22200 of 25000\n",
      "Review 22300 of 25000\n",
      "Review 22400 of 25000\n",
      "Review 22500 of 25000\n",
      "Review 22600 of 25000\n",
      "Review 22700 of 25000\n",
      "Review 22800 of 25000\n",
      "Review 22900 of 25000\n",
      "Review 23000 of 25000\n",
      "Review 23100 of 25000\n",
      "Review 23200 of 25000\n",
      "Review 23300 of 25000\n",
      "Review 23400 of 25000\n",
      "Review 23500 of 25000\n",
      "Review 23600 of 25000\n",
      "Review 23700 of 25000\n",
      "Review 23800 of 25000\n",
      "Review 23900 of 25000\n",
      "Review 24000 of 25000\n",
      "Review 24100 of 25000\n",
      "Review 24200 of 25000\n",
      "Review 24300 of 25000\n",
      "Review 24400 of 25000\n",
      "Review 24500 of 25000\n",
      "Review 24600 of 25000\n",
      "Review 24700 of 25000\n",
      "Review 24800 of 25000\n",
      "Review 24900 of 25000\n",
      "CPU times: user 1min 29s, sys: 2.18 s, total: 1min 31s\n",
      "Wall time: 2min 29s\n"
     ]
    }
   ],
   "source": [
    "%time trainDataVecs = reviewFeatureVec(getCleanReviews(train), model, num_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyunkyungbae/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 25000\n",
      "Review 2000 of 25000\n",
      "Review 3000 of 25000\n",
      "Review 4000 of 25000\n",
      "Review 5000 of 25000\n",
      "Review 6000 of 25000\n",
      "Review 7000 of 25000\n",
      "Review 8000 of 25000\n",
      "Review 9000 of 25000\n",
      "Review 10000 of 25000\n",
      "Review 11000 of 25000\n",
      "Review 12000 of 25000\n",
      "Review 13000 of 25000\n",
      "Review 14000 of 25000\n",
      "Review 15000 of 25000\n",
      "Review 16000 of 25000\n",
      "Review 17000 of 25000\n",
      "Review 18000 of 25000\n",
      "Review 19000 of 25000\n",
      "Review 20000 of 25000\n",
      "Review 21000 of 25000\n",
      "Review 22000 of 25000\n",
      "Review 23000 of 25000\n",
      "Review 24000 of 25000\n",
      "CPU times: user 1min 23s, sys: 1.57 s, total: 1min 24s\n",
      "Wall time: 2min 28s\n"
     ]
    }
   ],
   "source": [
    "%time testDataVecs = reviewFeatureVec(getCleanReviews(test), model, num_features )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "forest = forest.fit(trainDataVecs, train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = forest.predict(testDataVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(data = {'id':test['id'], 'sentiment':result})\n",
    "output.to_csv('part3-FeatureVecAvg.csv', header=0, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score: 0.78072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 2: Clustering\n",
    "\n",
    "방법 설명: \n",
    "Word2Vec 으로 구한 단어 벡터를 바탕으로 클러스터를 구성한 후, 각 Review 의 단어가 해당하는 클러스터 개수를 세어서 BOW 모델로 Feature 를 만든다. 만들어진 Feature 와 Training Data 의 Sentiment 로 Supervised Learning 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 진행하는 순서는 아래와 같다.\n",
    "1. KMeans 모델을 사용하여 word vector 클러스터 학습. 평균적으로 한 클러스터당 5개의 단어가 오도록 한다.\n",
    "2. 단어와 단어가 해당하는 클러스터 idx 의 정보를 가지고 있는 dictionary 생성\n",
    "3. training data 의 각 review 별로 구성하는 단어의 클러스터 idx 의 BOW 벡터 생성\n",
    "4. 클러스터의 BOW 와 training data 의 sentiment 로 랜덤포레스트 모델 학습\n",
    "5. 4번에서 생성한 모델로 predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = int(len(model.wv.index2word)/5)\n",
    "kmeans = KMeans(n_clusters = num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyunkyungbae/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for KMeans Clustering:  595.7671039104462\n"
     ]
    }
   ],
   "source": [
    "word_vectors = model.wv.syn0\n",
    "\n",
    "start = time.time()\n",
    "idx = kmeans.fit_predict(word_vectors)\n",
    "end = time.time()\n",
    "elapsed = end-start\n",
    "print('Time taken for KMeans Clustering: ', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 단어와 단어가 해당하는 클러스터 idx 의 정보를 가지고 있는 dictionary 생성\n",
    "idx = list(idx)\n",
    "words_lst = model.wv.index2word\n",
    "word_centroid_map = {words_lst[i]:idx[i] for i in range(len(words_lst))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluser number: 0\n",
      "['prejudice', 'rebellion', 'equality', 'discrimination', 'pretext']\n",
      "Cluser number: 1\n",
      "['noticeably']\n",
      "Cluser number: 2\n",
      "['sinatra', 'warren', 'beatty', 'oates', 'mchugh']\n",
      "Cluser number: 3\n",
      "['haunted', 'owned', 'visited', 'spotted']\n",
      "Cluser number: 4\n",
      "['hapless', 'pesky']\n",
      "Cluser number: 5\n",
      "['hare', 'mal', 'venom', 'sabu', 'veidt']\n",
      "Cluser number: 6\n",
      "['roman', 'frontier', 'colonial', 'geisha', 'crusades', 'royalty', 'carandiru', 'geography', 'predominantly', 'postwar', 'continental', 'mayan', 'heartland', 'province', 'warsaw']\n",
      "Cluser number: 7\n",
      "['implications', 'contents']\n",
      "Cluser number: 8\n",
      "['whistle', 'hut', 'peach']\n",
      "Cluser number: 9\n",
      "['break', 'fly', 'block', 'sink', 'lift', 'climb', 'ladder', 'crawl', 'penetrate']\n"
     ]
    }
   ],
   "source": [
    "# 클러스터 확인\n",
    "for no_cluster in range(0,10):\n",
    "    print('Cluser number: {}'.format(no_cluster))\n",
    "    words = []\n",
    "    for i in range(0, len(list(word_centroid_map.values()))):\n",
    "        if (list(word_centroid_map.values())[i]==no_cluster):\n",
    "            words.append(list(word_centroid_map.keys())[i])\n",
    "    print(words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. training data 의 각 review 별로 구성하는 단어의 클러스터 idx 의 BOW 벡터 생성\n",
    "\n",
    "# BOW 를 계산하도록 각 review 를 단어의 리스트로 만든다\n",
    "clean_train_reviews = []\n",
    "for review in train['review']:\n",
    "    clean_train_reviews.append(KaggleWord2VecUtility.review_to_wordlist(review, remove_stopwords=True))\n",
    "\n",
    "clean_test_reviews = []\n",
    "for review in test['review']:\n",
    "    clean_test_reviews.append(KaggleWord2VecUtility.review_to_wordlist(review, remove_stopwords=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어로 구성된 리스트를 넣으면 단어가 해당된 클러스터 기준으로 BOW 결과를 출력하는 함수\n",
    "def create_bag_of_centroids(wordlist, word_centroid_map):\n",
    "    num_centroids = max(word_centroid_map.values())+1\n",
    "    bag_of_centroids = np.zeros(num_centroids, dtype='float32')\n",
    "    \n",
    "    for word in wordlist:\n",
    "        if word in word_centroid_map:\n",
    "            index = word_centroid_map[word]\n",
    "            bag_of_centroids[index] += 1\n",
    "\n",
    "    return bag_of_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_centroids = np.zeros((train['review'].size, num_clusters))\n",
    "test_centroids = np.zeros((test['review'].size, num_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for review in clean_train_reviews:\n",
    "    train_centroids[counter] = create_bag_of_centroids(review, word_centroid_map)\n",
    "    counter += 1\n",
    "\n",
    "    \n",
    "counter = 0\n",
    "for review in clean_test_reviews:\n",
    "    test_centroids[counter] = create_bag_of_centroids(review, word_centroid_map)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 클러스터의 BOW 와 training data 의 sentiment 로 랜덤포레스트 모델 학습\n",
    "\n",
    "cluster_forest = RandomForestClassifier(n_estimators=100)\n",
    "cluster_forest.fit(train_centroids, train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 4번에서 생성한 모델로 predict \n",
    "cluster_result = cluster_forest.predict(test_centroids)\n",
    "cluster_output = pd.DataFrame(data= {'id': test['id'], 'sentiment': cluster_result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_output.to_csv('part3_ClusteringBOW.csv', index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score: 0.81380"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
